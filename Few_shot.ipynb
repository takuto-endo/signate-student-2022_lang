{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Zero_shot.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMWgV6//iUhnFa/37DSLkSi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"194edc5517004954b6ba382355805dba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_817d1bd5247047c4974e9acf9d69ba79","IPY_MODEL_f282bc2f6c8c4379b37a56cc5bdb20cf","IPY_MODEL_ebf6e1be235e4ad2974a355028279252"],"layout":"IPY_MODEL_58c19b3c87234af88fb9291992f7af7e"}},"817d1bd5247047c4974e9acf9d69ba79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2472a097322f44ac84955c4305da4a88","placeholder":"​","style":"IPY_MODEL_c23c90f648a34f9b9a618edadcd9d400","value":"Downloading config.json: 100%"}},"f282bc2f6c8c4379b37a56cc5bdb20cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13974fddab9840af85be01fb614aa45e","max":1154,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85c8a8dc576b4ba29e1b5fe3c5575411","value":1154}},"ebf6e1be235e4ad2974a355028279252":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1619aff170b84f2fa573829be7ea3617","placeholder":"​","style":"IPY_MODEL_8d838a8c6a32430caa769bf72b44d9ea","value":" 1.13k/1.13k [00:00&lt;00:00, 22.9kB/s]"}},"58c19b3c87234af88fb9291992f7af7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2472a097322f44ac84955c4305da4a88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c23c90f648a34f9b9a618edadcd9d400":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13974fddab9840af85be01fb614aa45e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85c8a8dc576b4ba29e1b5fe3c5575411":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1619aff170b84f2fa573829be7ea3617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d838a8c6a32430caa769bf72b44d9ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec4d703344724713936aa831be31bddf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b1c52dca18f4506950aa2c0e8b25ecf","IPY_MODEL_e594af0b8df84bf987c2560dc9fcd12b","IPY_MODEL_8b61a0aab2024d2084ff03aaedda967c"],"layout":"IPY_MODEL_83757902a1964136b104419c903b3bc5"}},"2b1c52dca18f4506950aa2c0e8b25ecf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67d576bbcd6f49b18603ef9a810fa481","placeholder":"​","style":"IPY_MODEL_0d8cb445a57e4251884ae911acaba033","value":"Downloading pytorch_model.bin: 100%"}},"e594af0b8df84bf987c2560dc9fcd12b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_981a5892c295443fb79dc1e348f6362c","max":1629486723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f0a167f010540ccbb54348d594b73bd","value":1629486723}},"8b61a0aab2024d2084ff03aaedda967c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_827fe9c7c5234772b7e6162ddfa7e943","placeholder":"​","style":"IPY_MODEL_aa0d4b0a4ed94038a3ecca0c0b154484","value":" 1.52G/1.52G [00:29&lt;00:00, 59.3MB/s]"}},"83757902a1964136b104419c903b3bc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67d576bbcd6f49b18603ef9a810fa481":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d8cb445a57e4251884ae911acaba033":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"981a5892c295443fb79dc1e348f6362c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f0a167f010540ccbb54348d594b73bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"827fe9c7c5234772b7e6162ddfa7e943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa0d4b0a4ed94038a3ecca0c0b154484":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d37e5b20ad25415894674f5365f177e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1301b42497b546809db9dbe2fa090178","IPY_MODEL_c3f46342b23c41c2917edbd86768e9f4","IPY_MODEL_0ee4c855f4264c209b1d0ce23e1aa1d6"],"layout":"IPY_MODEL_d8d31e7f534f4321aa26ec93509d9ddc"}},"1301b42497b546809db9dbe2fa090178":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_166c14d9d8934e049e168db0a5fe9c4a","placeholder":"​","style":"IPY_MODEL_130ae126ae50454b8d0c6fbf064c9fdb","value":"Downloading tokenizer_config.json: 100%"}},"c3f46342b23c41c2917edbd86768e9f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24c4d97ba19a43a898ab7e875e5b7d06","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3e4cb0607294fe4a3c22bb94dc7020b","value":26}},"0ee4c855f4264c209b1d0ce23e1aa1d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41747fcea77049a59979fce50ac1f22c","placeholder":"​","style":"IPY_MODEL_acc914d3a7d6450684e073a0d0c8c5cf","value":" 26.0/26.0 [00:00&lt;00:00, 712B/s]"}},"d8d31e7f534f4321aa26ec93509d9ddc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"166c14d9d8934e049e168db0a5fe9c4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"130ae126ae50454b8d0c6fbf064c9fdb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24c4d97ba19a43a898ab7e875e5b7d06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3e4cb0607294fe4a3c22bb94dc7020b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41747fcea77049a59979fce50ac1f22c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acc914d3a7d6450684e073a0d0c8c5cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f383ec717a04f2285dfa65802147c8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68d3a34a98294a7fb55855a8fb442fb9","IPY_MODEL_dd8b6d6c8dad42f98b1880e69ad4f1e6","IPY_MODEL_dbbe250adea9434390de243461272116"],"layout":"IPY_MODEL_76fda5b79c384380b5f32025215c76bc"}},"68d3a34a98294a7fb55855a8fb442fb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69481fc5912049c1bb79687d75094cb7","placeholder":"​","style":"IPY_MODEL_3dc2558732d64563aa9173d780e83d5d","value":"Downloading vocab.json: 100%"}},"dd8b6d6c8dad42f98b1880e69ad4f1e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bb9b20885b54c1aba1fd8deead4d357","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0ffbae1b8fb418784c7bca21a4d64a5","value":898822}},"dbbe250adea9434390de243461272116":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0712bcebafd4511807e5df49fdc1898","placeholder":"​","style":"IPY_MODEL_c8a47e5d4dac4b32a7be759b2f1e23c0","value":" 878k/878k [00:00&lt;00:00, 2.99MB/s]"}},"76fda5b79c384380b5f32025215c76bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69481fc5912049c1bb79687d75094cb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dc2558732d64563aa9173d780e83d5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bb9b20885b54c1aba1fd8deead4d357":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0ffbae1b8fb418784c7bca21a4d64a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0712bcebafd4511807e5df49fdc1898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8a47e5d4dac4b32a7be759b2f1e23c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af316cdbccc8485081ca58e278a0f263":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6793e020d4ad441fb2c02dbc0e7a73d8","IPY_MODEL_55f6b72872a943d697ea1a26ed56deb9","IPY_MODEL_4aa096bc574d408982064347ad99807f"],"layout":"IPY_MODEL_8fd230e2664148288ee3331d99446cd4"}},"6793e020d4ad441fb2c02dbc0e7a73d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91aa48cbc55148168a622e89e67dd46f","placeholder":"​","style":"IPY_MODEL_6e1496e787ba477f92cce86a56c0331d","value":"Downloading merges.txt: 100%"}},"55f6b72872a943d697ea1a26ed56deb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e89c6c62a9641248c5ce5912ad30c2f","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_086a12aa12d347f1ae9fd6e9ef282fde","value":456318}},"4aa096bc574d408982064347ad99807f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aff3e8aee00744219ae09295afe74b56","placeholder":"​","style":"IPY_MODEL_69a677fb70554ca79a5f82f982bd5d58","value":" 446k/446k [00:00&lt;00:00, 1.40MB/s]"}},"8fd230e2664148288ee3331d99446cd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91aa48cbc55148168a622e89e67dd46f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e1496e787ba477f92cce86a56c0331d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e89c6c62a9641248c5ce5912ad30c2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"086a12aa12d347f1ae9fd6e9ef282fde":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aff3e8aee00744219ae09295afe74b56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69a677fb70554ca79a5f82f982bd5d58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f5e303981384610afaa0e8dc6a21e84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6bf590212da94a5a97b4bcd2087df4f2","IPY_MODEL_661a366af5284864a8901e1655b2350c","IPY_MODEL_a30bde84c4dd4bf6804cf3eb05512762"],"layout":"IPY_MODEL_2f4c1f27e7534a35bde615d4905534d5"}},"6bf590212da94a5a97b4bcd2087df4f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a191a16306ac4827b0934a15db8d330d","placeholder":"​","style":"IPY_MODEL_355b5afed8df40679425a93d2e72066c","value":"Downloading tokenizer.json: 100%"}},"661a366af5284864a8901e1655b2350c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40c6db9cfe1448e4a6c6b3b97b933e13","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_355fdf3116834677862d4a6ea31d0294","value":1355863}},"a30bde84c4dd4bf6804cf3eb05512762":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ced92eaf31de4d7f99a608191762d688","placeholder":"​","style":"IPY_MODEL_e8718c77c9e54580be2df98309dc8471","value":" 1.29M/1.29M [00:00&lt;00:00, 987kB/s]"}},"2f4c1f27e7534a35bde615d4905534d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a191a16306ac4827b0934a15db8d330d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"355b5afed8df40679425a93d2e72066c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40c6db9cfe1448e4a6c6b3b97b933e13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"355fdf3116834677862d4a6ea31d0294":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ced92eaf31de4d7f99a608191762d688":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8718c77c9e54580be2df98309dc8471":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"437b9d8f99dd46388c2ba2563002a787":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8442174a55774c808df01c4e0abd8bb3","IPY_MODEL_ad47730b70fe49a19cd6de3ebd29c96b","IPY_MODEL_f9d8c507fc4b47e4b7f2a2dd8d530355"],"layout":"IPY_MODEL_537c0e8c4dff40e08fce6648488fe44b"}},"8442174a55774c808df01c4e0abd8bb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6851b011e8d84c72b655404279081335","placeholder":"​","style":"IPY_MODEL_c620a120130349299e55e22bfda953f2","value":"100%"}},"ad47730b70fe49a19cd6de3ebd29c96b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1a92b1fe60640ba82723889e754a8de","max":1011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b44552eb149f487a930b2d2a24bd5758","value":1011}},"f9d8c507fc4b47e4b7f2a2dd8d530355":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cb6be206153403caeefb7b0d9da456c","placeholder":"​","style":"IPY_MODEL_466c1903e4454fb0bcf91669467b0028","value":" 1011/1011 [02:11&lt;00:00,  7.70ex/s]"}},"537c0e8c4dff40e08fce6648488fe44b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6851b011e8d84c72b655404279081335":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c620a120130349299e55e22bfda953f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1a92b1fe60640ba82723889e754a8de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b44552eb149f487a930b2d2a24bd5758":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9cb6be206153403caeefb7b0d9da456c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"466c1903e4454fb0bcf91669467b0028":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4ffb0de60c848bfa670dde5c254e064":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff0834d20ce841c48ee1e79154786e12","IPY_MODEL_1364b0c22e234afda2c58394f50cfb57","IPY_MODEL_e54ba2cda62149d093b4d2dbdec6bc75"],"layout":"IPY_MODEL_4026355c8a504c4c9ccc5c97266ff52e"}},"ff0834d20ce841c48ee1e79154786e12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b5b84f548784a9990e80458e28a471e","placeholder":"​","style":"IPY_MODEL_a61118d21e154b109428f56b74a70bf0","value":"100%"}},"1364b0c22e234afda2c58394f50cfb57":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08a77c3554ca4e2286e016f106c68240","max":1011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a0f5b67806348eb9313505c60adb995","value":1011}},"e54ba2cda62149d093b4d2dbdec6bc75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b34855e2fe5842f3bc0dc224d3b90f4c","placeholder":"​","style":"IPY_MODEL_f55c191c7c5a451ca64f34660c602f00","value":" 1011/1011 [00:00&lt;00:00, 4699.63ex/s]"}},"4026355c8a504c4c9ccc5c97266ff52e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b5b84f548784a9990e80458e28a471e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a61118d21e154b109428f56b74a70bf0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08a77c3554ca4e2286e016f106c68240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a0f5b67806348eb9313505c60adb995":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b34855e2fe5842f3bc0dc224d3b90f4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f55c191c7c5a451ca64f34660c602f00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"b9nUM8hQhzOG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660815514338,"user_tz":-540,"elapsed":27,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"c0316f88-9735-4aa4-da33-2705d50d9e30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Aug 18 09:38:34 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   56C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":[""],"metadata":{"id":"VtHoGTW9h_M5","executionInfo":{"status":"ok","timestamp":1660815514341,"user_tz":-540,"elapsed":12,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N-W3yEUXavgY"},"source":["# Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"TjoTdSidaxEV","executionInfo":{"status":"ok","timestamp":1660815536964,"user_tz":-540,"elapsed":22635,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"outputs":[],"source":["%%capture\n","!pip install transformers\n","!pip install pytorch-lightning"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"VFddvPR4a04K","executionInfo":{"status":"ok","timestamp":1660815539400,"user_tz":-540,"elapsed":2448,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"outputs":[],"source":["import gc\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import re\n","\n","import random\n","import torch\n","\n","def set_seed(seed=0):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","set_seed()\n","\n","import warnings\n","warnings.simplefilter('ignore')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"cRfjvBkva39H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660815561254,"user_tz":-540,"elapsed":21866,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"45d2e016-e1f2-4184-a18f-e53e9a9b0375"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive', force_remount=False)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"x5gsH0yNCjGA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660815561255,"user_tz":-540,"elapsed":16,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"ff8226b6-8a54-422f-df9f-3636feab3a25"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/signate_student_cup_2022\n"]}],"source":["%cd /content/drive/MyDrive/signate_student_cup_2022\n","train_path = './data/train.csv'\n","test_path = './data/test.csv'\n","submit_path = './data/submit_sample.csv'"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"cs1BSN3m_m4Q","executionInfo":{"status":"ok","timestamp":1660815561256,"user_tz":-540,"elapsed":10,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"outputs":[],"source":["job_flags = ['Data scientist', 'Machine learning engineer','Software engineer','Consultant']"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gSOp6Gboce9S","executionInfo":{"status":"ok","timestamp":1660815561256,"user_tz":-540,"elapsed":9,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"outputs":[],"source":["def text_cleaning(texts):\n","    clean_texts = []\n","    num_lines = []\n","    num_words = []\n","    words_chunk = []\n","    for text in texts:\n","        clean_lines = []\n","        # print(text, \"\\n\")\n","        lines = text.split(r\"</li>\")\n","        for line in lines:\n","            line = remove_tag(line)\n","            # print(line)\n","            #バックスラッシュをスペースに置き換え\n","            clean_line = re.sub(r'[\\\\]', '', line)\n","            # clean_line = re.sub(r'[/]', ' and ', line)# test\n","            # print(clean_line)\n","            clean_line = clean_line.strip()\n","            # print(clean_line, \"\\n\")\n","            clean_line = clean_line + ('' if clean_line.endswith('.') else '.')\n","            if len(clean_line)!=1:\n","                # print(clean_line, \"\\n\")\n","                clean_lines.append(clean_line)\n","        # print(clean_lines)\n","        clean_texts.append(' '.join(clean_lines))\n","        \n","        num_lines.append(len(clean_lines))\n","        num_word = len(str(clean_lines).split())\n","        num_words.append(num_word)\n","        word_chunk = ((num_word-1)//240)+1\n","        words_chunk.append(word_chunk)\n","\n","    return clean_texts, num_lines, num_words, words_chunk\n","\n","def remove_tag(x):\n","    p = re.compile(r\"<[^>]*?>\")\n","    return p.sub('',x)"]},{"cell_type":"code","source":["job_flags = ['Data scientist', 'Machine learning engineer','Software engineer','Consultant']\n","\n","train_data = pd.read_csv(train_path)\n","train_data['description'], num_lines, num_words, words_chunk = text_cleaning(train_data['description'])\n","for i in range(3):\n","  print(\"===== \", i, \" =====\")\n","  for j in range(10):\n","    temp_df = train_data[train_data[\"jobflag\"]==i+1].reset_index(drop=True)\n","    print(temp_df.loc[j, \"description\"], \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-0eQ3zjKhp8","executionInfo":{"status":"ok","timestamp":1660815562090,"user_tz":-540,"elapsed":843,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"23902924-beec-4a16-92c6-efd91e0ea5ed"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["=====  0  =====\n","Consolidate dashboards across the team and help to drive interpretation, socialization and adoption of operational sales reports. \n","\n","Maintain and improve existing predictive models to evaluate media efficacy and effectiveness, willing to develop new models to help answer business questions. Glean actionable insights to support in-market campaign optimization. Support proactive \"what-if\" analysis and guide marketing and advertising decision-making. Collaborate and partner with other agency departments -- Media, Brand Planning, PR/Social Influence,. \n","\n","Participate in communication of research methods, implementation, and results to varied audience of clinicians, scientists, analysts, and programmers. Contribute to manuscript writing for results publication, authors abstracts, and presents at professional conferences. Contribute to experiments and summaries for grant proposal preparation. \n","\n","Implement process improvements and automation for efficiency where appropriate. Design, build, and deploy reports. Perform analyses and draw meaningful, accurate conclusions to direct business decisions and create research documentation materials. Develop and maintain documentation that chronicles processes. \n","\n","Use AWS AI services (e.g., Personalize), ML platforms (SageMaker), and frameworks (e.g., MXNet, TensorFlow, PyTorch, SparkML, scikit-learn) to help our customers build ML models. Research and implement novel ML approaches, including hardware optimizations on platforms such as AWS Inferentia. \n","\n","Support and drive interpretation, socialization and adoption of operational marketing reports. Support design and implementation of experimentation necessary to improve channel efficiency, drive growth, and inform marketing investment decisions. \n","\n","Explore and evaluate new ML algorithms to optimize model performance for latency, availability, and accuracy. Publish and present new research at premier ML/CS conferences. \n","\n","The successful candidate will:. Perform industry research and develop summary materials. Use technical writing skills to prepare content for reports. \n","\n","Develop and deploy models in production using Python. Run A/B test experiments and analyze results. Communicate findings to non-technical audience. Stay current with new tools and techniques in the literature. \n","\n","Create Visualizations and report to articulate technical results. Assist in development of automating predictive modeling for surveillance. Act as a liaison between technical development and business users and provide solution. Work closely with application teams and communicate effectively and proactively. \n","\n","=====  1  =====\n","Optimize deep learning frameworks like TensorFlow, PyTorch, etc. on AMD GPUs in upstream open-source repositories. Collaborate and interact with internal GPU library teams to analyze and optimize training and inference for deep learning. Work in a distributed computing setting to optimize for both scale-up (multi-GPU) and scale-out (multi-node) systems. Work with cutting-edge compiler technologies. Optimize the entire deep learning pipeline including graph compiler integration. \n","\n","Research, prototype, identify, and build predictive products. You will write tests to ensure the robustness and reliability of your productionized models. You will guide and mentor team members and help educate the business on the art of the possible. \n","\n","Optimizing our ML model and methods for determining Liveness/Realness of human faces. Delivering optimized models to the app development team for integration in the apps. Communication with both internal and 3rd party technical teams who wish to integrate our models and/or SDK into their apps. \n","\n","Work together with the ML team to perform research, testing and evaluation of existing and emerging NLP/ML/DL methods and technologies that could be effectively applied to contractual/legal. Be knowledgeable in and be able to apply NLP techniques in order to maintain and extend the current rule-based, supervised and unsupervised methods. Be knowledgeable in and able to apply ML/DL algorithms and technologies to NLP tasks such as Named Entity Recognition, POS tagging, Parsing, Sentiment Analysis, Clustering, text prediction etc. Understand, assist and improved the existing training maintenance and enrichment process. \n","\n","Implementing appropriate ML algorithms. Research and implement appropriate ML algorithms and tools. Perform statistical analysis and fine-tuning using test results. Train and retrain systems when necessary. Extend existing ML libraries and frameworks. Keep abreast of developments in the field requirements. \n","\n","Contribute to decision-making that will lead to successful delivery of projects. \n","\n","Collaborate with multiple partner teams such as Business, Technology, Product Management, Legal, Compliance, Strategy and Business Management to deploy solutions into production. \n","\n","Working across the stack to build and deploy web applications. \n","\n","Build the next-generation platform to support our growth efforts across the world. \n","\n","Implement end-to-end management of the model lifecycle using MLOps practices. \n","\n","=====  2  =====\n","Develop cutting-edge web applications that perform superbly across all platforms. Work in a highly collaborative environment with cross-functional teams on projects ranging from a few weeks to a few months in length. Maintain high standard of quality as you creatively and strategically problem solve throughout the product delivery process. Be able to effectively communicate your work with both technical and non-technical peers. Be excited about new web technologies/techniques. Build solid front-end architectures that integrate easily with other systems and technologies. Working closely with other disciplines (Back-end, UX, Design, QA). Have a superior attention to detail and a strong ability to Q/A one's own work required, including cross-browser and cross-platform displays and performance. \n","\n","Designs and develops high quality, scalable and efficient solutions and products on schedule. Engages with system users and business analysts to identify system enhancements and/or new applications to meet business needs. Actively contributes to the development of solutions and ideas that add value. Proactively performs extensive system testing to ensure that the systems work efficiently and are developed following the applicable development methodology. Provides support during meetings as required; prepares and takes dictation, minutes, agendas, notices and manages mailings of meeting agendas and supporting materials. Must have experience with Java, Spring MVC, Web Services, Unit Testing, etc. Provides accurate and timely input to Scrum Master regarding status of technical tasks for self and team. Creates Unit tests to ensure accuracy. Tracks record of identifying largest risk areas and driving resolution of these issues. Leads the design, development and implementation of complex systems. Effectively and actively plays the role of technical advisor for projects, providing advice on tools, process and design to others. Shows initiative to initiate and actively facilitate meetings and issue resolution. Ensures project goals make sense and overall development objectives are being met. Assists in planning and organizing meetings/conference calls. Serves as a contact person in support of more serious production problems/issues. Any combination of relevant education and experience and/or related professional designations/certifications in this field is highly desirable. \n","\n","Work on the technical design, development, release and deployment of cloud-based infrastructure and applications. Working with, and supporting, the development team with application configuration for deployment, monitoring and other automation. Provide operational management and support of Linux and Windows servers and containers, including server hardening, patching, network security and log management to deliver web application and service stacks. Mentor and collaborate with other team members. Provide on-call/out of hours support, as part of a rota with other team members. \n","\n","Participates in standard business and technical information technology solution implementations, upgrades, enhancements, and conversions. Uses appropriate tools to analyze, identify, and resolve business and/or technical problems. Interacts with the customer to gain an understanding of the business environment and technical context. Validates scope, plans, and deliverables for assigned projects. \n","\n","System architecture - collaborating with senior team members. Technology evaluation - staying abreast of latest technological developments, prototype new methods to improve product quality and performance, and to extend or augment current products. Constantly monitor industry for new tools/libraries to aid in application development. Assist in the development of standards for design and implementation. Provide technical support to internal customers. Continue to upgrade technical and personal skills through internal and external training. \n","\n","Act as a senior developer to a team developing automation solutions. Collaborates with project collaborators to identify product and technical requirements. Conducts analysis to resolve integration needs. Works with a diverse team of architects, product owners, program managers, and other specialists of varying subject areas. Excellent problem-solving, collaboration skills and demonstrate initiative. \n","\n","Implement SharePoint solutions in Office365 and Power Platform. Create document libraries, custom lists and their corresponding features. Develop and maintain a product backlog and features list (as needed). Interface with business users in a professional manner to understand their requirements and analyze requirements in order to plan and develop solutions. Ability to travel, overnight up to 10%. Authorization to work in the US without sponsorship. \n","\n","Build scalable responsive Web Applications using Angular as per the UX designs supporting localization. Build high-performing Services layer using Python, FastAPI, AWS Lambda, SQS etc. Build Serverless applications using AWS cloud native technologies. Collaborate with Product teams to understand the customer requirements, provide accurate estimates and adhere to the project deadlines. Build Unit Tests Design, implement, test and maintain server-side components and web application. Participate in all scrum team activities and work closely with peers to achieve continuous improvement. Identify and embrace new technologies to enhance the customer experience, improve the platform stability, scalability and availability. Collaborate with global teams Development, QA, DevOps, Program Management teams to successfully deliver projects. \n","\n","Manages the design and development process for both objective and performance assessments, including milestones and timelines, and tracks progress. Communicates project status updates to cross-functional teams and stakeholders. Works with cross-functional teams to ensure projects have appropriate resources and realistic timelines and to solve any content-related issues regarding the assessments. Organizes and facilitates workshops for internal assessment development and review. Oversees subject matter expert involvement in the design, development, and review processes, as well as in the validation of an assessment’s congruency and accuracy. Maintains assessment design and development standards to ensure assessment integrity. Identifies and mitigates risks that may impact the quality or on-time delivery of assessments. Collaborates with the assessment team to define and execute assessment policies, processes, and best practices. Ensures alignment and consistency of assessments to WGU’s business objectives. Develops and implements item- and exam-level scoring guidelines and validates the successful implementation of these guidelines. Oversees assessment QA processes, identifying and resolving issues and trends, as required. Maintains knowledge of exam performance and makes necessary quality improvement adjustments throughout the exam lifecycle. Participates in cross-functional team to implement exam security measures. Performs other related duties as assigned. \n","\n","Provide technical expertise to implement and deliver various web and other system projects. Gather and analyze requirements, design and development of the projects. Organize and participate in review sessions and contribute to design insights for the projects. Develop good quality projects in a challenging timeframe and assist other members of the team. Participate in system testing to ensure quality deliverables. Contribute to the development and continuous review of the existing projects as well as participate in view and scope of future projects. Interface with program managers and other developers for project-based assignments. Contribute to and has responsibility for completion of assigned project. \n","\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XzKvs8EZbYDE","colab":{"base_uri":"https://localhost:8080/","height":837},"executionInfo":{"status":"ok","timestamp":1660815562091,"user_tz":-540,"elapsed":24,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"01b695ab-95aa-49f6-8e2e-4e8f9b61f7e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["4    505\n","1    468\n","3    455\n","2     88\n","Name: jobflag, dtype: int64\n","1    468\n","3    455\n","2     88\n","Name: jobflag, dtype: int64\n"]},{"output_type":"execute_result","data":{"text/plain":["    id                                        description  jobflag  num_lines  \\\n","0    0  Develop cutting-edge web applications that per...        2          8   \n","1    1  Designs and develops high quality, scalable an...        2         15   \n","2    3  Work on the technical design, development, rel...        2          5   \n","3    5  Participates in standard business and technica...        2          4   \n","4    8  Consolidate dashboards across the team and hel...        0          1   \n","5    9  Maintain and improve existing predictive model...        0          4   \n","6   10  Optimize deep learning frameworks like TensorF...        1          5   \n","7   11  Participate in communication of research metho...        0          3   \n","8   13  Research, prototype, identify, and build predi...        1          3   \n","9   14  System architecture - collaborating with senio...        2          6   \n","10  15  Implement process improvements and automation ...        0          4   \n","11  17  Use AWS AI services (e.g., Personalize), ML pl...        0          2   \n","12  19  Support and drive interpretation, socializatio...        0          2   \n","13  22  Act as a senior developer to a team developing...        2          5   \n","14  24  Implement SharePoint solutions in Office365 an...        2          6   \n","15  26  Explore and evaluate new ML algorithms to opti...        0          2   \n","16  27  The successful candidate will:. Perform indust...        0          3   \n","17  29  Build scalable responsive Web Applications usi...        2          8   \n","18  30  Develop and deploy models in production using ...        0          4   \n","19  31  Manages the design and development process for...        2         14   \n","\n","    num_words  words_chunk  \n","0         112            1  \n","1         221            1  \n","2          79            1  \n","3          49            1  \n","4          17            1  \n","5          53            1  \n","6          64            1  \n","7          41            1  \n","8          39            1  \n","9          72            1  \n","10         37            1  \n","11         39            1  \n","12         29            1  \n","13         52            1  \n","14         65            1  \n","15         24            1  \n","16         20            1  \n","17        110            1  \n","18         30            1  \n","19        191            1  "],"text/html":["\n","  <div id=\"df-d2eeeae3-08d0-4a8a-b6e3-95facbbb2e9b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>jobflag</th>\n","      <th>num_lines</th>\n","      <th>num_words</th>\n","      <th>words_chunk</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Develop cutting-edge web applications that per...</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>112</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Designs and develops high quality, scalable an...</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>221</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Work on the technical design, development, rel...</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>79</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>Participates in standard business and technica...</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>49</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8</td>\n","      <td>Consolidate dashboards across the team and hel...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>17</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>9</td>\n","      <td>Maintain and improve existing predictive model...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>53</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>10</td>\n","      <td>Optimize deep learning frameworks like TensorF...</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>64</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>11</td>\n","      <td>Participate in communication of research metho...</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>41</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>13</td>\n","      <td>Research, prototype, identify, and build predi...</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>39</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>14</td>\n","      <td>System architecture - collaborating with senio...</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>72</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>15</td>\n","      <td>Implement process improvements and automation ...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>37</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>17</td>\n","      <td>Use AWS AI services (e.g., Personalize), ML pl...</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>39</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>19</td>\n","      <td>Support and drive interpretation, socializatio...</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>29</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>22</td>\n","      <td>Act as a senior developer to a team developing...</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>52</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>24</td>\n","      <td>Implement SharePoint solutions in Office365 an...</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>65</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>26</td>\n","      <td>Explore and evaluate new ML algorithms to opti...</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>24</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>27</td>\n","      <td>The successful candidate will:. Perform indust...</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>20</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>29</td>\n","      <td>Build scalable responsive Web Applications usi...</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>110</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>30</td>\n","      <td>Develop and deploy models in production using ...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>30</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>31</td>\n","      <td>Manages the design and development process for...</td>\n","      <td>2</td>\n","      <td>14</td>\n","      <td>191</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2eeeae3-08d0-4a8a-b6e3-95facbbb2e9b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d2eeeae3-08d0-4a8a-b6e3-95facbbb2e9b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d2eeeae3-08d0-4a8a-b6e3-95facbbb2e9b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["train_data = pd.read_csv(train_path)\n","print(train_data[\"jobflag\"].value_counts())\n","train_data = train_data[train_data[\"jobflag\"]!=4].reset_index(drop=True)\n","print(train_data[\"jobflag\"].value_counts())\n","train_data['description'], num_lines, num_words, words_chunk = text_cleaning(train_data['description'])\n","train_data['num_lines'] = num_lines\n","train_data['num_words'] = num_words\n","train_data['words_chunk'] = words_chunk\n","train_data['jobflag'] = train_data['jobflag']-1\n","train_data.head(20)"]},{"cell_type":"code","source":["train_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5QsreAbHshzA","executionInfo":{"status":"ok","timestamp":1660815562949,"user_tz":-540,"elapsed":866,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"e31aefdf-8da9-44e7-9c54-093009e96813"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1011, 6)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","execution_count":11,"metadata":{"id":"wi4n8nOIbdRk","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1660815562950,"user_tz":-540,"elapsed":20,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"37648810-fbf3-4c30-f503-bfbffe743238"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     id                                        description  num_lines  \\\n","0  1516  Building decision-making models and proposing ...          2   \n","1  1517  Educate homeowners on the benefits of solar en...          5   \n","2  1518  Design, develop, document, and implement web a...          8   \n","3  1519  Apply advanced technical expertise and skills ...          6   \n","4  1520  Project manage and deliver against our roadmap...          4   \n","\n","   num_words  words_chunk  \n","0         30            1  \n","1         43            1  \n","2         82            1  \n","3         81            1  \n","4         35            1  "],"text/html":["\n","  <div id=\"df-45897402-d1e5-4ef7-9d3e-c212a7120891\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>num_lines</th>\n","      <th>num_words</th>\n","      <th>words_chunk</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>Building decision-making models and proposing ...</td>\n","      <td>2</td>\n","      <td>30</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>Educate homeowners on the benefits of solar en...</td>\n","      <td>5</td>\n","      <td>43</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>Design, develop, document, and implement web a...</td>\n","      <td>8</td>\n","      <td>82</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>Apply advanced technical expertise and skills ...</td>\n","      <td>6</td>\n","      <td>81</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>Project manage and deliver against our roadmap...</td>\n","      <td>4</td>\n","      <td>35</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45897402-d1e5-4ef7-9d3e-c212a7120891')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-45897402-d1e5-4ef7-9d3e-c212a7120891 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-45897402-d1e5-4ef7-9d3e-c212a7120891');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["test_data = pd.read_csv(test_path)\n","test_data['description'], num_lines, num_words, words_chunk = text_cleaning(test_data['description'])\n","test_data['num_lines'] = num_lines\n","test_data['num_words'] = num_words\n","test_data['words_chunk'] = words_chunk\n","test_data.head(5)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"pcBKDX7qbh80","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1660815563397,"user_tz":-540,"elapsed":464,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"538bd2be-262c-445c-94a8-ed2b3b0fd0ee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   1516  1\n","0  1517  1\n","1  1518  1\n","2  1519  1\n","3  1520  1\n","4  1521  1"],"text/html":["\n","  <div id=\"df-aefc5a41-8842-42ce-97fc-bf72073b03b3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1516</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1517</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1518</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1519</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1520</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1521</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aefc5a41-8842-42ce-97fc-bf72073b03b3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aefc5a41-8842-42ce-97fc-bf72073b03b3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aefc5a41-8842-42ce-97fc-bf72073b03b3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}],"source":["submit_df = pd.read_csv(submit_path)\n","submit_df.head(5)"]},{"cell_type":"code","source":[""],"metadata":{"id":"Pvdcty-RhVdT","executionInfo":{"status":"ok","timestamp":1660815563400,"user_tz":-540,"elapsed":18,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t1n1edqvcSi0"},"source":["# Dataset"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"euMQLsEWcBkK","executionInfo":{"status":"ok","timestamp":1660815566473,"user_tz":-540,"elapsed":3090,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from transformers import AutoTokenizer\n","import pytorch_lightning as pl\n","# pl.seed_everything(0, workers=True)\n","from torch.utils.data import DataLoader\n","from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n","import torch.nn as nn\n","import math\n","import torch.nn.functional as F\n","from torchmetrics import F1Score\n","from transformers import AutoConfig\n","\n","from torchmetrics.functional import precision_recall\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3tH0Coh2cXvQ","executionInfo":{"status":"ok","timestamp":1660815566474,"user_tz":-540,"elapsed":7,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"outputs":[],"source":["class Careers_Dataset(Dataset):\n","\n","  def __init__(self, data):\n","    self.data = data\n","    \n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, index):\n","    item = self.data.iloc[index]\n","    return item\n"]},{"cell_type":"markdown","source":["# Classification"],"metadata":{"id":"m8j2-pz-hXp5"}},{"cell_type":"code","source":["from transformers import pipeline\n","# pipe = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n","# pipe = pipeline(\"zero-shot-classification\", device=0)# best\n","pipe = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0)"],"metadata":{"id":"WhiIkGBtI-SN","colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["194edc5517004954b6ba382355805dba","817d1bd5247047c4974e9acf9d69ba79","f282bc2f6c8c4379b37a56cc5bdb20cf","ebf6e1be235e4ad2974a355028279252","58c19b3c87234af88fb9291992f7af7e","2472a097322f44ac84955c4305da4a88","c23c90f648a34f9b9a618edadcd9d400","13974fddab9840af85be01fb614aa45e","85c8a8dc576b4ba29e1b5fe3c5575411","1619aff170b84f2fa573829be7ea3617","8d838a8c6a32430caa769bf72b44d9ea","ec4d703344724713936aa831be31bddf","2b1c52dca18f4506950aa2c0e8b25ecf","e594af0b8df84bf987c2560dc9fcd12b","8b61a0aab2024d2084ff03aaedda967c","83757902a1964136b104419c903b3bc5","67d576bbcd6f49b18603ef9a810fa481","0d8cb445a57e4251884ae911acaba033","981a5892c295443fb79dc1e348f6362c","7f0a167f010540ccbb54348d594b73bd","827fe9c7c5234772b7e6162ddfa7e943","aa0d4b0a4ed94038a3ecca0c0b154484","d37e5b20ad25415894674f5365f177e7","1301b42497b546809db9dbe2fa090178","c3f46342b23c41c2917edbd86768e9f4","0ee4c855f4264c209b1d0ce23e1aa1d6","d8d31e7f534f4321aa26ec93509d9ddc","166c14d9d8934e049e168db0a5fe9c4a","130ae126ae50454b8d0c6fbf064c9fdb","24c4d97ba19a43a898ab7e875e5b7d06","c3e4cb0607294fe4a3c22bb94dc7020b","41747fcea77049a59979fce50ac1f22c","acc914d3a7d6450684e073a0d0c8c5cf","2f383ec717a04f2285dfa65802147c8e","68d3a34a98294a7fb55855a8fb442fb9","dd8b6d6c8dad42f98b1880e69ad4f1e6","dbbe250adea9434390de243461272116","76fda5b79c384380b5f32025215c76bc","69481fc5912049c1bb79687d75094cb7","3dc2558732d64563aa9173d780e83d5d","7bb9b20885b54c1aba1fd8deead4d357","e0ffbae1b8fb418784c7bca21a4d64a5","b0712bcebafd4511807e5df49fdc1898","c8a47e5d4dac4b32a7be759b2f1e23c0","af316cdbccc8485081ca58e278a0f263","6793e020d4ad441fb2c02dbc0e7a73d8","55f6b72872a943d697ea1a26ed56deb9","4aa096bc574d408982064347ad99807f","8fd230e2664148288ee3331d99446cd4","91aa48cbc55148168a622e89e67dd46f","6e1496e787ba477f92cce86a56c0331d","8e89c6c62a9641248c5ce5912ad30c2f","086a12aa12d347f1ae9fd6e9ef282fde","aff3e8aee00744219ae09295afe74b56","69a677fb70554ca79a5f82f982bd5d58","3f5e303981384610afaa0e8dc6a21e84","6bf590212da94a5a97b4bcd2087df4f2","661a366af5284864a8901e1655b2350c","a30bde84c4dd4bf6804cf3eb05512762","2f4c1f27e7534a35bde615d4905534d5","a191a16306ac4827b0934a15db8d330d","355b5afed8df40679425a93d2e72066c","40c6db9cfe1448e4a6c6b3b97b933e13","355fdf3116834677862d4a6ea31d0294","ced92eaf31de4d7f99a608191762d688","e8718c77c9e54580be2df98309dc8471"]},"executionInfo":{"status":"ok","timestamp":1660815611180,"user_tz":-540,"elapsed":44711,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"980e6734-8a90-4784-b4e8-13bc9f9cb21a"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"194edc5517004954b6ba382355805dba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec4d703344724713936aa831be31bddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d37e5b20ad25415894674f5365f177e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f383ec717a04f2285dfa65802147c8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af316cdbccc8485081ca58e278a0f263"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f5e303981384610afaa0e8dc6a21e84"}},"metadata":{}}]},{"cell_type":"markdown","source":["## zero-shot test"],"metadata":{"id":"L14wi0RCs2CF"}},{"cell_type":"code","source":["# tokenizer = AutoTokenizer.from_pretrained(\"zero-shot-classification\")\n","true_labels = ['Data scientist', 'Machine learning engineer','Software engineer','Consultant']\n","all_labels = ['Data scientist', 'Machine learning engineer','Software engineer']\n","label_mapping = {'Data scientist': 0, 'Machine learning engineer': 1,'Software engineer': 2}\n","\n","ds = Careers_Dataset(train_data)\n","\n","for i in range(3):\n","\n","  sample = ds[i]\n","  print(f\"Labels: {sample['jobflag']} >> {true_labels[sample['jobflag']]}\")\n","\n","  if sample['jobflag'] == 3:\n","    print(sample[\"description\"])\n","    print(\"\\n ===============================================\")\n","    continue\n","\n","  output = pipe(sample[\"description\"], all_labels)\n","  print(output[\"labels\"][0])\n","  print(label_mapping[output[\"labels\"][0]])\n","  # print(output[\"sequence\"][:400])\n","  print(\"[Predictions]\")\n","  for label, score in zip(output[\"labels\"], output[\"scores\"]):\n","      print(f\"{label}, {score:.2f}\")\n","\n","  print(\"\\n ===============================================\")\n","\n","# 特に不均衡データにはzero-shotありか... consultant抜きで考えてみる"],"metadata":{"id":"F9vfWueDhEnL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660815614062,"user_tz":-540,"elapsed":2903,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"8db05c1d-461a-4715-d6cf-c75e86bf5a2b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Labels: 2 >> Software engineer\n","Software engineer\n","2\n","[Predictions]\n","Software engineer, 0.60\n","Machine learning engineer, 0.22\n","Data scientist, 0.18\n","\n"," ===============================================\n","Labels: 2 >> Software engineer\n","Software engineer\n","2\n","[Predictions]\n","Software engineer, 0.77\n","Machine learning engineer, 0.12\n","Data scientist, 0.11\n","\n"," ===============================================\n","Labels: 2 >> Software engineer\n","Software engineer\n","2\n","[Predictions]\n","Software engineer, 0.71\n","Data scientist, 0.15\n","Machine learning engineer, 0.14\n","\n"," ===============================================\n"]}]},{"cell_type":"code","source":["# tokenizer = AutoTokenizer.from_pretrained(\"zero-shot-classification\")\n","true_labels = ['Data scientist', 'Machine learning engineer','Software engineer','Consultant']\n","all_labels = ['Data scientist', 'Machine learning engineer','Software engineer', 'Adviser']\n","\n","ds = Careers_Dataset(train_data)\n","\n","for i in range(20):\n","\n","  sample = ds[i]\n","  print(f\"Labels: {sample['jobflag']} >> {true_labels[sample['jobflag']]}\")\n","\n","  output = pipe(sample[\"description\"], all_labels)\n","  # print(output[\"sequence\"][:400])\n","  print(\"[Predictions]\")\n","  for label, score in zip(output[\"labels\"], output[\"scores\"]):\n","      print(f\"{label}, {score:.2f}\")\n","\n","  print(\"\\n ===============================================\")\n","\n","# 特に不均衡データにはzero-shotありか... consultant抜きで考えてみる"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hotKp0DgrjXe","executionInfo":{"status":"ok","timestamp":1660815617942,"user_tz":-540,"elapsed":3916,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"dd325ad9-ce46-40b6-dcc6-3d015a89cfb5"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Labels: 2 >> Software engineer\n","[Predictions]\n","Software engineer, 0.40\n","Adviser, 0.34\n","Machine learning engineer, 0.14\n","Data scientist, 0.12\n","\n"," ===============================================\n","Labels: 2 >> Software engineer\n","[Predictions]\n","Adviser, 0.60\n","Software engineer, 0.30\n","Machine learning engineer, 0.05\n","Data scientist, 0.04\n","\n"," ===============================================\n","Labels: 2 >> Software engineer\n","[Predictions]\n","Adviser, 0.50\n","Software engineer, 0.36\n","Data scientist, 0.08\n","Machine learning engineer, 0.07\n","\n"," ===============================================\n","Labels: 2 >> Software engineer\n","[Predictions]\n","Adviser, 0.48\n","Software engineer, 0.26\n","Machine learning engineer, 0.13\n","Data scientist, 0.13\n","\n"," ===============================================\n","Labels: 0 >> Data scientist\n","[Predictions]\n","Adviser, 0.48\n","Data scientist, 0.25\n","Software engineer, 0.16\n","Machine learning engineer, 0.11\n","\n"," ===============================================\n","Labels: 0 >> Data scientist\n","[Predictions]\n","Adviser, 0.34\n","Data scientist, 0.28\n","Machine learning engineer, 0.25\n","Software engineer, 0.14\n","\n"," ===============================================\n","Labels: 1 >> Machine learning engineer\n","[Predictions]\n","Machine learning engineer, 0.46\n","Software engineer, 0.28\n","Data scientist, 0.15\n","Adviser, 0.12\n","\n"," ===============================================\n","Labels: 0 >> Data scientist\n","[Predictions]\n","Adviser, 0.48\n","Data scientist, 0.22\n","Software engineer, 0.17\n","Machine learning engineer, 0.13\n","\n"," ===============================================\n","Labels: 1 >> Machine learning engineer\n","[Predictions]\n","Adviser, 0.42\n","Machine learning engineer, 0.23\n","Software engineer, 0.18\n","Data scientist, 0.17\n","\n"," ===============================================\n","Labels: 2 >> Software engineer\n","[Predictions]\n","Adviser, 0.51\n","Software engineer, 0.31\n","Machine learning engineer, 0.09\n","Data scientist, 0.09\n","\n"," ===============================================\n","Labels: 0 >> Data scientist\n","[Predictions]\n","Adviser, 0.41\n","Data scientist, 0.23\n","Software engineer, 0.20\n","Machine learning engineer, 0.16\n","\n"," ===============================================\n","Labels: 0 >> Data scientist\n","[Predictions]\n","Machine learning engineer, 0.41\n","Adviser, 0.25\n","Data scientist, 0.19\n","Software engineer, 0.15\n","\n"," ===============================================\n","Labels: 0 >> Data scientist\n","[Predictions]\n","Adviser, 0.52\n","Data scientist, 0.18\n","Machine learning engineer, 0.16\n","Software engineer, 0.14\n","\n"," ===============================================\n","Labels: 2 >> Software engineer\n","[Predictions]\n","Software engineer, 0.43\n","Adviser, 0.42\n","Machine learning engineer, 0.08\n","Data scientist, 0.07\n","\n"," ===============================================\n","Labels: 2 >> Software engineer\n","[Predictions]\n","Software engineer, 0.48\n","Adviser, 0.41\n","Data scientist, 0.07\n","Machine learning engineer, 0.05\n","\n"," ===============================================\n","Labels: 0 >> Data scientist\n","[Predictions]\n","Machine learning engineer, 0.51\n","Data scientist, 0.20\n","Software engineer, 0.14\n","Adviser, 0.14\n","\n"," ===============================================\n","Labels: 0 >> Data scientist\n","[Predictions]\n","Adviser, 0.37\n","Data scientist, 0.28\n","Software engineer, 0.24\n","Machine learning engineer, 0.12\n","\n"," ===============================================\n","Labels: 2 >> Software engineer\n","[Predictions]\n","Software engineer, 0.70\n","Adviser, 0.20\n","Data scientist, 0.05\n","Machine learning engineer, 0.05\n","\n"," ===============================================\n","Labels: 0 >> Data scientist\n","[Predictions]\n","Software engineer, 0.34\n","Machine learning engineer, 0.26\n","Data scientist, 0.22\n","Adviser, 0.19\n","\n"," ===============================================\n","Labels: 2 >> Software engineer\n","[Predictions]\n","Adviser, 0.47\n","Machine learning engineer, 0.20\n","Software engineer, 0.18\n","Data scientist, 0.16\n","\n"," ===============================================\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"D0L519XwO92q","executionInfo":{"status":"ok","timestamp":1660815617943,"user_tz":-540,"elapsed":33,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## zero-shot predicting"],"metadata":{"id":"6QKQTZy_s4vx"}},{"cell_type":"code","source":["# Zero-shotだとConsultantに過敏に反応: 3種類でやってみる → zero-shotがMachine learning engineerと予測したとこだけ入れ替える??\n","# binary分類でMachine learning engineerだけはやる?? <> Debartaは3or4種類分類"],"metadata":{"id":"BerludbKm122","executionInfo":{"status":"ok","timestamp":1660815617944,"user_tz":-540,"elapsed":32,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rlWWk-h7yP3f","executionInfo":{"status":"ok","timestamp":1660815623794,"user_tz":-540,"elapsed":5881,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"b5963205-e705-43da-cb64-61ad9a3e4ebc"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 66.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 73.4 MB/s \n","\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 71.9 MB/s \n","\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}}]},{"cell_type":"code","source":["from datasets import Dataset\n","\n","\"\"\"\n","all_labels = ['Data scientist', 'Machine learning engineer','Software engineer']\n","label_mapping = {'Data scientist': 0, 'Machine learning engineer': 1,'Software engineer': 2}\n","\"\"\"\n","\n","\"\"\"\n","all_labels = ['Data scientist', 'AI engineer','Software engineer']\n","label_mapping = {'Data scientist': 0, 'AI engineer': 1,'Software engineer': 2}\n","\"\"\"\n","\n","\"\"\"\n","all_labels = ['Data Science', 'Artificial Intelligence', 'Software']\n","label_mapping = {'Data Science': 0, 'Artificial Intelligence': 1,'Software': 2}\n","\"\"\"\n","\n","# tensor(0.6898)  [0.7573033707865169, 0.5, 0.8122362869198311]\n","\"\"\"\n","Data scientist \n","[[458  85]\n"," [131 337]]\n","Precision:  0.7985781990521327\n","Recall:  0.7200854700854701\n","\n"," Machine learning engineer \n","[[873  50]\n"," [ 42  46]]\n","Precision:  0.4791666666666667\n","Recall:  0.5227272727272727\n","\n"," Software engineer \n","[[448 108]\n"," [ 70 385]]\n","Precision:  0.7809330628803245\n","Recall:  0.8461538461538461\n","all_labels = ['Data Analysis', 'Machine Learning Engineering', 'Software Engineering']\n","label_mapping = {'Data Analysis': 0, 'Machine Learning Engineering': 1,'Software Engineering': 2}\n","\"\"\"\n","# TN FP\n","# FN TP\n","\n","all_labels = ['Data Analysis', 'Machine Learning Engineering', 'Software Engineering']\n","label_mapping = {'Data Analysis': 0, 'Machine Learning Engineering': 1,'Software Engineering': 2}\n","\n","\n","# all_labels = ['Data Analysis', 'AI', 'Software Engineering']\n","# label_mapping = {'Data Analysis': 0, 'AI': 1,'Software Engineering': 2}\n","\n","def zero_shot_pipeline(example):\n","    output = pipe(example[\"description\"], all_labels)\n","    example[\"predicted_labels\"] = output[\"labels\"]\n","    example[\"scores\"] = output[\"scores\"]\n","    return example\n","\n","ds = Dataset.from_pandas(train_data.reset_index(drop=True))\n","ds_zero_shot = ds.map(zero_shot_pipeline)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["437b9d8f99dd46388c2ba2563002a787","8442174a55774c808df01c4e0abd8bb3","ad47730b70fe49a19cd6de3ebd29c96b","f9d8c507fc4b47e4b7f2a2dd8d530355","537c0e8c4dff40e08fce6648488fe44b","6851b011e8d84c72b655404279081335","c620a120130349299e55e22bfda953f2","b1a92b1fe60640ba82723889e754a8de","b44552eb149f487a930b2d2a24bd5758","9cb6be206153403caeefb7b0d9da456c","466c1903e4454fb0bcf91669467b0028"]},"id":"zvazSQ_AueQl","executionInfo":{"status":"ok","timestamp":1660815762392,"user_tz":-540,"elapsed":138618,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"61b0b589-4ece-43e8-b24b-5253dc4ef89d"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1011 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"437b9d8f99dd46388c2ba2563002a787"}},"metadata":{}}]},{"cell_type":"code","source":["ds_zero_shot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-v83DZuxUCf","executionInfo":{"status":"ok","timestamp":1660815762392,"user_tz":-540,"elapsed":24,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"cc796f64-fc83-4b67-f3b5-c30261cad663"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['id', 'description', 'jobflag', 'num_lines', 'num_words', 'words_chunk', 'predicted_labels', 'scores'],\n","    num_rows: 1011\n","})"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["def get_preds(example, threshold=None, topk=None):\n","    return {\"predicted_ids\": label_mapping[example[\"predicted_labels\"][0]]}"],"metadata":{"id":"pvVLVz3UzUL-","executionInfo":{"status":"ok","timestamp":1660815762400,"user_tz":-540,"elapsed":27,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["ds_zero_shot = ds_zero_shot.map(get_preds, batched=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["a4ffb0de60c848bfa670dde5c254e064","ff0834d20ce841c48ee1e79154786e12","1364b0c22e234afda2c58394f50cfb57","e54ba2cda62149d093b4d2dbdec6bc75","4026355c8a504c4c9ccc5c97266ff52e","8b5b84f548784a9990e80458e28a471e","a61118d21e154b109428f56b74a70bf0","08a77c3554ca4e2286e016f106c68240","2a0f5b67806348eb9313505c60adb995","b34855e2fe5842f3bc0dc224d3b90f4c","f55c191c7c5a451ca64f34660c602f00"]},"id":"ujnu3Zlc0qg9","executionInfo":{"status":"ok","timestamp":1660815763102,"user_tz":-540,"elapsed":729,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"a43bc28d-9a40-49a8-b376-8963fd68628b"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1011 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4ffb0de60c848bfa670dde5c254e064"}},"metadata":{}}]},{"cell_type":"code","source":["ds_zero_shot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hfGAmV2S0okz","executionInfo":{"status":"ok","timestamp":1660815763103,"user_tz":-540,"elapsed":36,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"3f505c7b-4c25-48ee-d5d0-6e8c2ac3504f"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['id', 'description', 'jobflag', 'num_lines', 'num_words', 'words_chunk', 'predicted_labels', 'scores', 'predicted_ids'],\n","    num_rows: 1011\n","})"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["from torchmetrics import F1Score\n","f1_func = F1Score(num_classes=4, average=\"macro\")\n","\n","F1_labels = [\"DS\", \"ML\", \"SE\"]\n","def get_F1_score(ds):\n","    y_true = torch.tensor(ds[\"jobflag\"])\n","    y_pred = torch.tensor(ds[\"predicted_ids\"])\n","\n","    print(len(y_true))\n","\n","    for t in range(3):\n","        print(f'[{F1_labels[t]}]')\n","        for p in range(3):\n","            if t==p:\n","                # 正解\n","                print(f'● pred={F1_labels[p]} >> {(sum((y_true==t)&(y_pred==p)) / sum(y_true==t))*100 :.2f}')\n","            else:\n","                # 不正解\n","                print(f' × pred={F1_labels[p]} >> {sum((y_true==t)&(y_pred==p)) / sum(y_true==t)*100 :.2f}')\n","        print(\"\\n\")\n","    return f1_func(y_pred, y_true)# 実装\n","\n","def get_each_F1_score(ds):\n","    labels = np.array(ds[\"jobflag\"])\n","    predicted = np.array(ds[\"predicted_ids\"])\n","\n","    label_f1_scores = []\n","    for l in range(3):\n","        print(\"\\n\", ['Data scientist', 'Machine learning engineer','Software engineer'][l], \"\\n\")\n","        temp_predicted = np.where(predicted==l, 1, 0)\n","        temp_labels = np.where(labels==l, 1, 0)\n","        con_matrix = confusion_matrix(temp_labels, temp_predicted)\n","        print(con_matrix)\n","        TN = con_matrix[0][0]\n","        FP = con_matrix[0][1]\n","        FN = con_matrix[1][0]\n","        TP = con_matrix[1][1]\n","        precision = TP/(TP+FP)\n","        recall = TP/(TP+FN)\n","        print(\"Precision: \", precision)\n","        print(\"Recall: \", recall)\n","        temp_f1 = (2*precision*recall) / (precision+recall)\n","        label_f1_scores.append(temp_f1)\n","\n","        fn_point = (temp_predicted==0) == (temp_labels==1)\n","        # print(\"FN: 偽陰性\")\n","        for i in range(10):\n","            # print(\"\\n    \", np.array(ds[\"description\"])[fn_point][i])\n","            pass\n","\n","        fp_point = (temp_predicted==1) == (temp_labels==0)\n","        # print(\"FP: 偽陽性\")\n","        for i in range(10):\n","            # print(\"\\n    \", np.array(ds[\"description\"])[fp_point][i])\n","            pass\n","\n","    return label_f1_scores# 実装"],"metadata":{"id":"eS7WXMXLzfd-","executionInfo":{"status":"ok","timestamp":1660815763103,"user_tz":-540,"elapsed":32,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["f1_score = get_F1_score(ds_zero_shot)\n","f1_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-u-BOBn73lvd","executionInfo":{"status":"ok","timestamp":1660815763103,"user_tz":-540,"elapsed":31,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"b49792b7-e1d7-4a47-e3e8-3bcf6d159fbd"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["1011\n","[DS]\n","● pred=DS >> 72.01\n"," × pred=ML >> 9.83\n"," × pred=SE >> 18.16\n","\n","\n","[ML]\n"," × pred=DS >> 21.59\n","● pred=ML >> 52.27\n"," × pred=SE >> 26.14\n","\n","\n","[SE]\n"," × pred=DS >> 14.51\n"," × pred=ML >> 0.88\n","● pred=SE >> 84.62\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(0.6898)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# ['Data scientist', 'Machine learning engineer','Software engineer']\n","each_f1_score = get_each_F1_score(ds_zero_shot)\n","each_f1_score\n","# TN FP\n","# FN TP"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"caiAnM4E1fe4","executionInfo":{"status":"ok","timestamp":1660815763104,"user_tz":-540,"elapsed":30,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"2c0f2aed-984f-459b-bf90-465d9068b9bb"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Data scientist \n","\n","[[458  85]\n"," [131 337]]\n","Precision:  0.7985781990521327\n","Recall:  0.7200854700854701\n","\n"," Machine learning engineer \n","\n","[[873  50]\n"," [ 42  46]]\n","Precision:  0.4791666666666667\n","Recall:  0.5227272727272727\n","\n"," Software engineer \n","\n","[[448 108]\n"," [ 70 385]]\n","Precision:  0.7809330628803245\n","Recall:  0.8461538461538461\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7573033707865169, 0.5, 0.8122362869198311]"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":[""],"metadata":{"id":"9P7BECI-3rHw","executionInfo":{"status":"ok","timestamp":1660815763106,"user_tz":-540,"elapsed":28,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["for desc in train_data[train_data[\"jobflag\"]==1][\"description\"].reset_index(drop=True):\n","    print(desc, \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YcGu6f43gA6j","executionInfo":{"status":"ok","timestamp":1660815763107,"user_tz":-540,"elapsed":28,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"e44382ca-23a3-4b31-ae98-0a04bdc72483"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimize deep learning frameworks like TensorFlow, PyTorch, etc. on AMD GPUs in upstream open-source repositories. Collaborate and interact with internal GPU library teams to analyze and optimize training and inference for deep learning. Work in a distributed computing setting to optimize for both scale-up (multi-GPU) and scale-out (multi-node) systems. Work with cutting-edge compiler technologies. Optimize the entire deep learning pipeline including graph compiler integration. \n","\n","Research, prototype, identify, and build predictive products. You will write tests to ensure the robustness and reliability of your productionized models. You will guide and mentor team members and help educate the business on the art of the possible. \n","\n","Optimizing our ML model and methods for determining Liveness/Realness of human faces. Delivering optimized models to the app development team for integration in the apps. Communication with both internal and 3rd party technical teams who wish to integrate our models and/or SDK into their apps. \n","\n","Work together with the ML team to perform research, testing and evaluation of existing and emerging NLP/ML/DL methods and technologies that could be effectively applied to contractual/legal. Be knowledgeable in and be able to apply NLP techniques in order to maintain and extend the current rule-based, supervised and unsupervised methods. Be knowledgeable in and able to apply ML/DL algorithms and technologies to NLP tasks such as Named Entity Recognition, POS tagging, Parsing, Sentiment Analysis, Clustering, text prediction etc. Understand, assist and improved the existing training maintenance and enrichment process. \n","\n","Implementing appropriate ML algorithms. Research and implement appropriate ML algorithms and tools. Perform statistical analysis and fine-tuning using test results. Train and retrain systems when necessary. Extend existing ML libraries and frameworks. Keep abreast of developments in the field requirements. \n","\n","Contribute to decision-making that will lead to successful delivery of projects. \n","\n","Collaborate with multiple partner teams such as Business, Technology, Product Management, Legal, Compliance, Strategy and Business Management to deploy solutions into production. \n","\n","Working across the stack to build and deploy web applications. \n","\n","Build the next-generation platform to support our growth efforts across the world. \n","\n","Implement end-to-end management of the model lifecycle using MLOps practices. \n","\n","Collaborate with the application development team to integrate the computer vision models with the existing backend systems. Build monitoring and evaluation tools for real-time optimization of the application using hardware accelerators. Inspire the entire team (including your cross-functional) partners by bringing new ideas to the table. \n","\n","Uses technical expertise with tools/applications (i.e., Cadence, RTL Compiler, etc.) to execute advanced architecture and design of multiple complex blocks and makes suggestions for design protocol. Leads the development of an implementation strategy that meets system requirements and customer needs for team. Works effectively with incomplete, ambiguous or conflicting requirements to successfully resolve complex architecture, design, or verification problems. Reviews the design and verification strategies of ASICs, SoC, and IP cores of team members and develops strategies for complex blocks or IC Packages. Reviews highly complex tests from more junior team members and completes own tests to ensure that bugs are fully understood and analyzed. Runs advanced power checks on multiple complex blocks to ensure design specifications are met; makes recommendations to leadership when specifications are not met. Reviews reports and oversees the process of interpreting reports derived from performance checks to ensure major issues are identified. Stays up to date on technical literature and technological advances and supports the creation of new technology. Regularly communicates with key cross-functional groups (i.e., product management, program management teams) to determine product execution path and communicates this path to team. Drives technical conversation in design or project reviews and project meetings to ensure team's progress on project tasks and best interests are represented. Acts as a tech lead on large projects and owns the outcome of the project. \n","\n","Identify and recreate customer’s issues in lab environment to recommend and clearly communicate resolutions. Work independently and with other members of the technical support team to resolve customer application issues in a timely fashion. Collaborate with Product Managers and Product Design Team in HQ to resolve technical issues and suggest product improvements. Create sample applications, product demos, technical documents and other related items for sales, marketing, and support efforts. Provide technical product training to sales team, channel partners, system integrators, OEMs, and end users. Maintain and improve current knowledge through personal education and training. Stay abreast of upcoming product releases as well as current and future technological trends. Interface with customers in the field in support of new projects or investigate potential quality issues. Other duties as assigned. \n","\n","Development of optimization algorithms for ML operators/layers for the Qualcomm AI SW stack. Development of AI SW stack framework enhancements for optimal resource usage while running a neural network on Qualcomm hardware. Evaluating and optimizing neural networks runtime performance and accuracy. Working with customer teams to enable state of the art network models and new AI SW features to meet customer use-cases. Collaborating with AI Hardware and architecture teams to continuously improve our AI solution. \n","\n","Foster Google’s culture and principles within the UX team, while working with the UX Research Manager and UX Program Manager to set standards in executional and operational excellence. Provide leadership, direction, and mentorship for a team of designers across multiple products/solutions. Work with the team to drive strategic alignment across Cloud Healthcare and Life Sciences products and identify opportunities for product alignment opportunities across the Cloud AI and Industry Solutions organization. Build excellent relationships with leaders to efficiently implement user experiences that are cohesive, inclusive, and well-informed. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form. https://careers.google.com/jobs/results/115997018309960390-ux-design-manager/ FULL_TIME Google en-US Waterloo ON Canada USER_EXPERIENCE onsite NoMinimum qualifications:12 years of experience in UX Design. 3 years of experience in managing or leading design teams. A portfolio of UX-focused work samples for web and mobile application. Preferred qualifications:Experience building solutions that are comprised of many products and services. Experience with Command Line Interfaces/API design and/or developer tools. Experience establishing Accessibility focus for products. Ability to communicate complex interaction concepts clearly and persuasively across different audiences and varying levels of the organization. \n","\n","Perform experiments and statistical analyses to draw conclusions and take modeling decisions. Study, implement and extend state of the art systems. Take part in regular research reviews and discussions. Build, maintain and extend our open source solutions in the domain. \n","\n","Build and maintain pipelines and benchmarks to improve model performance. Optimize the training process for deep learning models. Design in-truck validation experiments and conduct full-system integration and tests. \n","\n","Conceptualize novel computational approaches for prioritizing disease-associated splice variants. Benchmark these methods against existing baseline approaches e.g. using simulations. Document and present progress and results in written or oral reports to other lab members. Prepare manuscripts and external presentations including for consortium meetings. Building standardized Python and conda packages. \n","\n","Build the large scale systems for ML integrating with GPU, RDMA network and storage system;. \n","\n","Maintain and improve ML SW automation test framework. Test case development from feature requirements and use case analysis. Working with development team for regression report triage, bug analysis and issue tracking. \n","\n","Research, prototype, identify, and build predictive products. You will write tests to ensure the robustness and reliability of your productionized models. \n","\n","Actively participate in scoping requirements, ML pipeline design and development, (on-device) ML model development, evaluation and validation. \n","\n","Help us build out our MLOps system for tracking, maintaining, interpreting, and retraining our production models. Effectively communicate complex technical results to business partners. Work with a great deal of autonomy to find solutions to complex problems. You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. \n","\n","Research, analyse and translate business, market and user requirements and innovative ideas. Collect customer requirements and analyse feasibility, cost and potential benefits. Participate in internal and external dev events such as hackathons, dev/research conferences. \n","\n","You will get to learn the ins and outs of building core capabilities &amp; API products that can scale globally. Should be able to design, build and work with RESTful Web Services in JSON and XML formats. (Flask preferred). Should follow Agile principles and processes including (but not limited to) standup meetings, sprints and retrospectives. \n","\n","Be a part of a cross-functional product team (2-week sprints), deliver on business objectives by collaborating with your team. Play an active role in raising the excellence level of the team, coaching more junior team members. Identify pain points at the team or company level, either on the operational or business level, and set up tools, processes, and other initiatives to improve and solve the problems in the long term. Solve bugs, be able to investigate our ML pipeline to find root causes. Solve identity-related problems: document detection, document verification, OCR, face detection and recognition, face liveness detection, etc. \n","\n","Experience in container, streaming and messaging technologies is a plus. \n","\n","Develop algorithms to exploit information in various sensor systems. Develop models of signal processing outputs to support system understanding. Coordinate algorithm delivery to implementation and deployment teams. Other related functions as assigned. \n","\n","Work closely with library developers to adopt and use these compiler technologies to enable library development. Work closely with open-source maintainers to have your changes adopted. Work in a distributed compute setting to optimize for both scale-up (multi-GPU) and scale-out (multi-node) systems. \n","\n","Deploy deep learning models for BioCatch’s authentication and fraud detection capabilities. Assist researchers by automating model training pipelines. Monitor health of respective production services. Requirements:. \n","\n","Work on high-impact projects and innovate new solutions to problems in the self-driving space. \n","\n","Training / Test model. Work on Azure Cognitive Services to improve document processing services. Contribute towards design and implementation of the overall application architecture. Building middle-tier services to deliver AI/ML capabilities front-end application. Identify and understand improvement opportunities. Proactive in identifying workarounds, fix bugs, implement changes. Self-driven and able to work independently to take projects to completion with minimum supervision. \n","\n","Applies advanced principles, theories, and concepts, particularly in the area of algorithms for AI/ML/DL, to Army mission sets. Contributes to the development of innovative principles and ideas. Works on unusually complex problems and provides solutions that are highly creative. Provides advice and counsel to the organization in area of expertise. Utilize modeling and simulation tools to advance research, design, and development. Contribute to technical paper writing and presentation as required for conferences and symposia. \n","\n","Deliver MLOps workflow. \n","\n","You will be dedicated to a small cross-discipline product team, with tremendous ownership and responsibility for guiding things directly. You will develop high impact solutions to support Algolia's AI ambitious growth plans. You will have the freedom to suggest and drive organization-wide AI initiatives. \n","\n","Work closely with library developers to adopt and use these compiler technologies to enable library development. Work closely with open-source maintainers to have your changes adopted. Work in a distributed compute setting to optimize for both scale-up (multi-GPU) and scale-out (multi-node) systems. \n","\n","Research and prototype perception deep learning systems for our level 4 self-driving system. \n","\n","Join our core animation technology team and work closely with performance capture, animation, rigging, technical art, and tools teams across different Rockstar studios. Research, develop, maintain, extend, and support a wide range of image/video/mesh processing, surface reconstruction, animation, and rigging performance capture technology, editing pipelines, tools, and runtime systems. Keep up to date with the latest academic and industry breakthroughs, independently research and develop improvements to continuously push our technology forward. \n","\n","Collaborate with the application development team to integrate computer vision models with existing backend systems. Collaborate with product leads to design A/B testing experiments with ML technology and improve predictability through end-to-end solutions. Develop CI/CD pipelines for deployment on the cloud. \n","\n","Develop metrics that reveal neural network performance, thereby providing actionable information for improving the models. Deploy trained neural networks on a real-time surgical robotic system. \n","\n","Building, deploying and maintaining ML models and pipelines. Developing robust and scalable pipelines. Working collaboratively with the ML Lead and the wider team. \n","\n","Be a key participant of the team’s Agile process. Actively monitors relevant KPIs for productionized models. Note - Working in a DevOps model, this opportunity includes both building and running solutions that could require off hours support. This support is shared amongst the team members to cover weekends and weeknights. The goal is to design for failure and, using cloud-native infrastructure patterns, automate responses to issues so they can be worked during normal hours. \n","\n","Design and implement new models or extend existing models. Develop new visualization techniques. Maintain and develop CI/CD workflows. \n","\n","Collaborate with scientists to integrate successful experiments into large scale, highly complex production services. Rapidly design and conduct large scale experiments in a high-ambiguity environment, making use of both quantitative and business judgment. \n","\n","Develop new algorithms and approaches to various NLP problems. Conduct quantitative experiments to characterize algorithms. Integrate new technology into core applications. \n","\n","Research and develop improvements to our open-banking transaction enrichment pipeline. Lead new projects that improve the capabilities of our open-banking enrichment pipeline (such as transaction categorisation, merchant tagging, and balance prediction). Work as part of the team on downstream tasks like credit risk modelling and fraud detectionImplement, monitor and maintain models in our AWS production environment. \n","\n","Designing, training, improving &amp; launching models. Proposing and implementing ideas that directly reduce Stripe’s fraud losses. Building systems that evaluate businesses for risk and take appropriate actions. Working with our partner teams to launch new policies that directly impact Stripe’s bottom line. Debugging production issues across services and multiple levels of the stack. Who you areWe’re looking for someone who meets the minimum requirements to be considered for the role. If you meet these requirements, you are encouraged to apply. The preferred qualifications are a bonus, not a requirement. \n","\n","Build state-of-the-art models for various modeling tasks (e.g., NLP, search ranking and recommendation). Optimize and automate model training and testing, experimentation tracking, development, and production. Create ML services/APIs for serving ML/AI model results. Skilled in breaking down problems, documenting problem statements and estimating efforts. \n","\n","Create ML pipelines using container native workflow orchestration. Build centralized featureset store for both online and offline training. Support and improve our recommendation pipelines and platform utilizing Spark &amp; (Scala / Python), tooling and integrations with cloud services. Respond to on-calls and alerts on our live pipelines. Participate in discussions, team rituals and be an amplifier to the work of the team. \n","\n","Keep track of emerging tech and trends, research the state-of-art deep learning models, prototype new modelling ideas, and conduct offline and online experiments. Mentor other team members, facilitate within/across team workshops and lead the agile development. \n","\n","Hands-on in creating architectural prototypes and design implementation to demonstrate the vision in ML/AI solutions and lead the way from concept to realization. May be assigned an Electric Utilities emergency and storm role. This is a special assignment that comes into play during storms and other emergencies when the company needs to restore power or respond to other issues affecting customer service. This role may necessitate the need to work after-hours, outside of your normal schedule. \n","\n","Design NLP applications. Use effective text representations to transform natural language into useful features. Find and implement the right algorithms and tools for NLP/ML tasks. Develop ML/NLP systems according to requirements. Perform statistical analysis of results and refine models. \n","\n","Participate in cutting-edge applications for neurotechnology and brain-computer interfaces. Utilize cloud compute infrastructure for high-throughput hypothesis modeling and simulation. Translate validated algorithms for clinical deployment (both online and offline). Summarize and communicate results to project teams and contribute to decision-making. Collaborate with the rest of our team to publish and present our work. \n","\n","Support and improve our recommendation pipelines and platform utilizing Spark &amp; (Scala / Python), tooling and integrations with cloud services. Enable research scientists to accelerate experimentation using platforms and tools. Create pipelines using container native workflow orchestration. Respond to on-calls and alerts on our live pipelines. Participate in discussions, team rituals and be an amplifier to the work of the team. \n","\n","Design and develop state-of-art ML model development and orchestration framework. Design optimal Model run-time instances to improve model run-time, cut-down compute cost. Collaborate with Technical Product Managers to influence the scope, capabilities and roadmap of ML Platform. Articulate and document best practices and design principles to mentor other developers. Research and evaluate new open-source technologies and framework to solve problems &amp; improve existing solutions. Articulate and present the business value of your product design to different stakeholders and user. \n","\n","Understand organizational challenges and how integrating AI capabilities can help create solutions. Lead cross-functional teams to identify and prioritize key areas of business where AI solutions can drive significant business benefit. Advise business leaders on a broad range of technology, strategy, and policy issues associated with AI. Document and articulate solution architecture and lessons learned for each exploration and accelerated incubation. Manage a team to conduct assessments of the AI and automation market and competitive landscape. Ensuring that algorithms generate accurate user recommendations. Running tests, performing statistical analysis, and interpreting test results. \n","\n","Collaborate with the application development team to integrate computer vision models with existing backend systems. Collaborate with product leads to design A/B testing experiments with ML technology and improve predictability through end-to-end solutions. Develop CI/CD pipelines for deployment on the cloud. \n","\n","Work with sales partners to identify business opportunities for advertisers' business goals. \n","\n","Follow best practices in development and CI/CD methods and test-driven development. \n","\n","Implement and deploy robust audio-related generative models and classifiers. Work closely with researchers to convert research prototypes into production-ready systems. Set up, monitor and maintain inference pipelines. Optimize models for on-device inference. Keep up to date with the latest ML/AI research trends and industry best practices. \n","\n","Presenting solutions and technical reasoning to experts and non-experts. \n","\n","reinforcement learning, (v)AE, GAN, GCNN. predictive (QSAR) models. knowledge graph mining and analyses algorithms. Present the results of the team findings within the company and at external events. Publish and disseminate your work in research community. Depending on experience, mentoring and line management responsibilities may be part of the role. \n","\n","Develop, port, and optimize ML/DL applications and frameworks including HPC use cases for use on AMD hardware. Work with other members of the Applications Solutions team to collaboratively solve issues. Represent AMD to customers and other third parties, and act as the customer advocate when presenting to AMD audiences. Engage with AMD product groups to drive resolution of customer issues. Develop and present training materials to internal audiences, at customer venues, and at industry conferences. \n","\n","Implement and test the latest research works. \n","\n","Support in building models and algorithms. Meets project deadlines for accountable deliverables and anticipates delays or foreseeable barriers to progress, escalating issues when necessary. Conducts due diligence quality assurance testing for prototypes and tools in beta and resolves reoccurring complex issues and bugs. Experiences Demonstrated success when deciding on technical methodologies for project work. Consistently delivered accurate, technically advanced and valid analyses with impactful insights and conclusions. \n","\n","Perform prototyping in real-world and simulation experiments to validate architecture / algorithm designs and technical approaches. Perform troubleshooting to rapidly characterize and address issues within the fleet. \n","\n","Build and maintain robust ML pipelines. Implement monitoring systems to track how models are performing. Work to continuously improve model performance and debug where necessary. Manage the memory and computational footprint of our algorithms. \n","\n","Collaborate with the Advanced Development Architect and other Product Architects as well as product management team to translate system architecture and product requirements into well implemented components. Contribute as a hands-on Individual Contributor or Project Lead committed to team success, willing to do the simple or complicated tasks to move a project forward. \n","\n","You will be the main ML generalist at the organizations, helping provide efficient production and deployment. Please register your interest by sending your CV to Jaashir Morris via the Apply link on this page. \n","\n","Promote and support company policies, procedures, mission, values, and standards of ethics and integrity. \n","\n","Understand how to break work down into concise deliverables with a focus on iterative product delivery. Own solutions end to end from conception to release by managing complexity and collaboratively working with various stakeholders to achieve desired outcomes. Debug and resolve issues across multiple technology stacks and services. \n","\n","Build recommendation and ranking algorithms for news articles. Lead medium/large sized projects to improve news ranking. \n","\n","Provide guidance to measure and optimize the quality of deployed algorithms and models ( processes and best practices). Build and maintain the CI/CD pipeline for ML. Be an active member of the business transformationWork with stakeholders including the Executives, CX, Design and Dev teams to assist with related complex technical conversations and support their AI-based product needs. Be an inspirational and motivational colleagueShare knowledge with team members &amp; participate in various learning-sharing activities. Contribute to the collaborative and stimulating work environment. Be a change agent &amp; Agile mindset promoter. Be connected to the industry to know tendencies and suggest innovative ideas. \n","\n","Work with stakeholders across hardware, science, and operations teams to iterate on systems design and implementation. Profile, tune, and optimize system performance. Maintain high standards by participating in reviews, designing for fault tolerance and operational excellence, and creating mechanisms for continuous improvement. Mentor junior team members. \n","\n","Applied behavioral scientist: Advance the understanding of behavior change and interventions by measuring quantitative and qualitative signals across a breadth of psychographic signals. Act as an owner: It’s not done until it’s in production. Adept at moving projects forward and able to unblock projects regardless of the role on the project. Do less, deliver more: Familiar with the terms YAGNI and yak shaving? Focus your efforts on high impact initiatives that really move the needle. Collaborate without ego: Willing to take on roles small or large in order to further the mission at hand. Stay on your edge: Continuously learning and applying emerging technologies. Pushing yourself and your team to new heights. \n","\n","You will be analyzing result sets to identify anomalies and historical norms and order to continuously improve the quality of the model's output and their usefulness in solving real life business problems. \n","\n","You will monitor deployed models for model drift and performance, support model retraining and provide incident management support. You will monitor deployed models for model drift and performance, support model retraining and provide incident management support. Bring your passion and expertise 2+ years’ experience deploying AI model pipelines in the Cloud (AWS preferred) and integrating AI/ML and other Cloud services into large-scale production applications. Proficiency in at least one modern programming language like Python and ML frameworks like Tensorflow, Scikit-learn, Pytorch , NumPy, Pandas etc. Solid understanding and 2+ years’ experience working with one of the cloud computing environments such as AWS, Azure, Google Cloud. Must possess strong verbal and written communication skills, be self-driven, accountable and constant learner. Experience working for a large retail company is preferred. \n","\n","Communicate and collaborate with a network of experienced architects and designers around the world. Identify complex technical problems, break them down, summarize possible solutions. Work with architects to propose innovative solutions that can be implemented in HW, validated by developing various models/simulators. \n","\n","Research and develop innovative ML based solutions to some of Operations' hardest problems. Communicate AI capabilities and results to both technical and non-technical audiences. Document approaches taken, techniques used and processes followed. \n","\n","Work with Product Managers to understand the business, formulate the problems, come up with the solutions. \n","\n","Collaborate with the application development team to integrate the computer vision models with the existing backend systems. Build monitoring tools and automate the inference pipeline. Develop CI/CD pipelines for deployment on cloud and edge. Inspire the entire team (including your cross-functional) partners by bringing new ideas to the table. \n","\n","Responsible for the development and maintenance of key system features. Will work with other team members to investigate design approaches, prototype technology and evaluate technical feasibility. Will establish architectural principles, select design patterns and then mentor team members on their appropriate application. Team Locations:Toronto. Vancouver. Virtual in Canada. Key job responsibilities. \n","\n","Pipeline Orchestration – design and development of end to end workflow/pipeline . Assist in development and deployment of automation and operational support strategies. Work in an Agile environment with Scrum teams. \n","\n","Build API endpoints. Work on Cloud deployment. \n","\n","Monitor, diagnose and maintain deployments. Upgrade systems and models whenever needed. Take care of product performance, robustness and reliability. Manage individual project priorities, deadlines and deliverables. General direction of work involved. \n","\n","Implementing appropriate ML algorithms. Demonstrable skill in deep learning (Kaggle Medal / Paper / Work / PhD). Research and implement appropriate ML algorithms and tools. Perform statistical analysis and fine-tuning using test results. Train and retrain systems when necessary. Extend existing ML libraries and frameworks. Keep abreast of developments in the field. \n","\n","Define problems and opportunities in a complex business area. Measure the impact of the products developed. \n","\n","Collaborate with teams to support the ML technical roadmap. Offer support and troubleshooting assistance for the ML pipeline, while continuously improving stability, monitoring and alerting along the way. Collaborate on managing the AWS stack which comprises all ML resources. Collaborate on managing ML infrastructure costs. \n","\n"]}]},{"cell_type":"code","source":["ds_zero_shot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aayx1A0MNeKK","executionInfo":{"status":"ok","timestamp":1660815763107,"user_tz":-540,"elapsed":21,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"c60d0560-d0e3-4cf3-f4ea-4a98ccb5b691"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['id', 'description', 'jobflag', 'num_lines', 'num_words', 'words_chunk', 'predicted_labels', 'scores', 'predicted_ids'],\n","    num_rows: 1011\n","})"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["F1_labels = [\"DS\", \"ML\", \"SE\"]\n","for example in ds_zero_shot:\n","    for p in range(3):\n","        if example['jobflag']==1 and example['predicted_ids']==p:\n","            print(f'pred={F1_labels[p]}')\n","            print(example['description'], \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IL_DWWUMMRs2","executionInfo":{"status":"ok","timestamp":1660815763541,"user_tz":-540,"elapsed":444,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}},"outputId":"4e31871c-6a51-4f62-c41a-96fbd2927a71"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["pred=ML\n","Optimize deep learning frameworks like TensorFlow, PyTorch, etc. on AMD GPUs in upstream open-source repositories. Collaborate and interact with internal GPU library teams to analyze and optimize training and inference for deep learning. Work in a distributed computing setting to optimize for both scale-up (multi-GPU) and scale-out (multi-node) systems. Work with cutting-edge compiler technologies. Optimize the entire deep learning pipeline including graph compiler integration. \n","\n","pred=ML\n","Research, prototype, identify, and build predictive products. You will write tests to ensure the robustness and reliability of your productionized models. You will guide and mentor team members and help educate the business on the art of the possible. \n","\n","pred=ML\n","Optimizing our ML model and methods for determining Liveness/Realness of human faces. Delivering optimized models to the app development team for integration in the apps. Communication with both internal and 3rd party technical teams who wish to integrate our models and/or SDK into their apps. \n","\n","pred=ML\n","Work together with the ML team to perform research, testing and evaluation of existing and emerging NLP/ML/DL methods and technologies that could be effectively applied to contractual/legal. Be knowledgeable in and be able to apply NLP techniques in order to maintain and extend the current rule-based, supervised and unsupervised methods. Be knowledgeable in and able to apply ML/DL algorithms and technologies to NLP tasks such as Named Entity Recognition, POS tagging, Parsing, Sentiment Analysis, Clustering, text prediction etc. Understand, assist and improved the existing training maintenance and enrichment process. \n","\n","pred=ML\n","Implementing appropriate ML algorithms. Research and implement appropriate ML algorithms and tools. Perform statistical analysis and fine-tuning using test results. Train and retrain systems when necessary. Extend existing ML libraries and frameworks. Keep abreast of developments in the field requirements. \n","\n","pred=DS\n","Contribute to decision-making that will lead to successful delivery of projects. \n","\n","pred=DS\n","Collaborate with multiple partner teams such as Business, Technology, Product Management, Legal, Compliance, Strategy and Business Management to deploy solutions into production. \n","\n","pred=SE\n","Working across the stack to build and deploy web applications. \n","\n","pred=SE\n","Build the next-generation platform to support our growth efforts across the world. \n","\n","pred=ML\n","Implement end-to-end management of the model lifecycle using MLOps practices. \n","\n","pred=SE\n","Collaborate with the application development team to integrate the computer vision models with the existing backend systems. Build monitoring and evaluation tools for real-time optimization of the application using hardware accelerators. Inspire the entire team (including your cross-functional) partners by bringing new ideas to the table. \n","\n","pred=SE\n","Uses technical expertise with tools/applications (i.e., Cadence, RTL Compiler, etc.) to execute advanced architecture and design of multiple complex blocks and makes suggestions for design protocol. Leads the development of an implementation strategy that meets system requirements and customer needs for team. Works effectively with incomplete, ambiguous or conflicting requirements to successfully resolve complex architecture, design, or verification problems. Reviews the design and verification strategies of ASICs, SoC, and IP cores of team members and develops strategies for complex blocks or IC Packages. Reviews highly complex tests from more junior team members and completes own tests to ensure that bugs are fully understood and analyzed. Runs advanced power checks on multiple complex blocks to ensure design specifications are met; makes recommendations to leadership when specifications are not met. Reviews reports and oversees the process of interpreting reports derived from performance checks to ensure major issues are identified. Stays up to date on technical literature and technological advances and supports the creation of new technology. Regularly communicates with key cross-functional groups (i.e., product management, program management teams) to determine product execution path and communicates this path to team. Drives technical conversation in design or project reviews and project meetings to ensure team's progress on project tasks and best interests are represented. Acts as a tech lead on large projects and owns the outcome of the project. \n","\n","pred=SE\n","Identify and recreate customer’s issues in lab environment to recommend and clearly communicate resolutions. Work independently and with other members of the technical support team to resolve customer application issues in a timely fashion. Collaborate with Product Managers and Product Design Team in HQ to resolve technical issues and suggest product improvements. Create sample applications, product demos, technical documents and other related items for sales, marketing, and support efforts. Provide technical product training to sales team, channel partners, system integrators, OEMs, and end users. Maintain and improve current knowledge through personal education and training. Stay abreast of upcoming product releases as well as current and future technological trends. Interface with customers in the field in support of new projects or investigate potential quality issues. Other duties as assigned. \n","\n","pred=ML\n","Development of optimization algorithms for ML operators/layers for the Qualcomm AI SW stack. Development of AI SW stack framework enhancements for optimal resource usage while running a neural network on Qualcomm hardware. Evaluating and optimizing neural networks runtime performance and accuracy. Working with customer teams to enable state of the art network models and new AI SW features to meet customer use-cases. Collaborating with AI Hardware and architecture teams to continuously improve our AI solution. \n","\n","pred=DS\n","Foster Google’s culture and principles within the UX team, while working with the UX Research Manager and UX Program Manager to set standards in executional and operational excellence. Provide leadership, direction, and mentorship for a team of designers across multiple products/solutions. Work with the team to drive strategic alignment across Cloud Healthcare and Life Sciences products and identify opportunities for product alignment opportunities across the Cloud AI and Industry Solutions organization. Build excellent relationships with leaders to efficiently implement user experiences that are cohesive, inclusive, and well-informed. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form. https://careers.google.com/jobs/results/115997018309960390-ux-design-manager/ FULL_TIME Google en-US Waterloo ON Canada USER_EXPERIENCE onsite NoMinimum qualifications:12 years of experience in UX Design. 3 years of experience in managing or leading design teams. A portfolio of UX-focused work samples for web and mobile application. Preferred qualifications:Experience building solutions that are comprised of many products and services. Experience with Command Line Interfaces/API design and/or developer tools. Experience establishing Accessibility focus for products. Ability to communicate complex interaction concepts clearly and persuasively across different audiences and varying levels of the organization. \n","\n","pred=DS\n","Perform experiments and statistical analyses to draw conclusions and take modeling decisions. Study, implement and extend state of the art systems. Take part in regular research reviews and discussions. Build, maintain and extend our open source solutions in the domain. \n","\n","pred=ML\n","Build and maintain pipelines and benchmarks to improve model performance. Optimize the training process for deep learning models. Design in-truck validation experiments and conduct full-system integration and tests. \n","\n","pred=DS\n","Conceptualize novel computational approaches for prioritizing disease-associated splice variants. Benchmark these methods against existing baseline approaches e.g. using simulations. Document and present progress and results in written or oral reports to other lab members. Prepare manuscripts and external presentations including for consortium meetings. Building standardized Python and conda packages. \n","\n","pred=ML\n","Build the large scale systems for ML integrating with GPU, RDMA network and storage system;. \n","\n","pred=ML\n","Maintain and improve ML SW automation test framework. Test case development from feature requirements and use case analysis. Working with development team for regression report triage, bug analysis and issue tracking. \n","\n","pred=ML\n","Research, prototype, identify, and build predictive products. You will write tests to ensure the robustness and reliability of your productionized models. \n","\n","pred=ML\n","Actively participate in scoping requirements, ML pipeline design and development, (on-device) ML model development, evaluation and validation. \n","\n","pred=ML\n","Help us build out our MLOps system for tracking, maintaining, interpreting, and retraining our production models. Effectively communicate complex technical results to business partners. Work with a great deal of autonomy to find solutions to complex problems. You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. \n","\n","pred=DS\n","Research, analyse and translate business, market and user requirements and innovative ideas. Collect customer requirements and analyse feasibility, cost and potential benefits. Participate in internal and external dev events such as hackathons, dev/research conferences. \n","\n","pred=SE\n","You will get to learn the ins and outs of building core capabilities &amp; API products that can scale globally. Should be able to design, build and work with RESTful Web Services in JSON and XML formats. (Flask preferred). Should follow Agile principles and processes including (but not limited to) standup meetings, sprints and retrospectives. \n","\n","pred=DS\n","Be a part of a cross-functional product team (2-week sprints), deliver on business objectives by collaborating with your team. Play an active role in raising the excellence level of the team, coaching more junior team members. Identify pain points at the team or company level, either on the operational or business level, and set up tools, processes, and other initiatives to improve and solve the problems in the long term. Solve bugs, be able to investigate our ML pipeline to find root causes. Solve identity-related problems: document detection, document verification, OCR, face detection and recognition, face liveness detection, etc. \n","\n","pred=SE\n","Experience in container, streaming and messaging technologies is a plus. \n","\n","pred=ML\n","Develop algorithms to exploit information in various sensor systems. Develop models of signal processing outputs to support system understanding. Coordinate algorithm delivery to implementation and deployment teams. Other related functions as assigned. \n","\n","pred=SE\n","Work closely with library developers to adopt and use these compiler technologies to enable library development. Work closely with open-source maintainers to have your changes adopted. Work in a distributed compute setting to optimize for both scale-up (multi-GPU) and scale-out (multi-node) systems. \n","\n","pred=ML\n","Deploy deep learning models for BioCatch’s authentication and fraud detection capabilities. Assist researchers by automating model training pipelines. Monitor health of respective production services. Requirements:. \n","\n","pred=ML\n","Work on high-impact projects and innovate new solutions to problems in the self-driving space. \n","\n","pred=ML\n","Training / Test model. Work on Azure Cognitive Services to improve document processing services. Contribute towards design and implementation of the overall application architecture. Building middle-tier services to deliver AI/ML capabilities front-end application. Identify and understand improvement opportunities. Proactive in identifying workarounds, fix bugs, implement changes. Self-driven and able to work independently to take projects to completion with minimum supervision. \n","\n","pred=ML\n","Applies advanced principles, theories, and concepts, particularly in the area of algorithms for AI/ML/DL, to Army mission sets. Contributes to the development of innovative principles and ideas. Works on unusually complex problems and provides solutions that are highly creative. Provides advice and counsel to the organization in area of expertise. Utilize modeling and simulation tools to advance research, design, and development. Contribute to technical paper writing and presentation as required for conferences and symposia. \n","\n","pred=ML\n","Deliver MLOps workflow. \n","\n","pred=SE\n","You will be dedicated to a small cross-discipline product team, with tremendous ownership and responsibility for guiding things directly. You will develop high impact solutions to support Algolia's AI ambitious growth plans. You will have the freedom to suggest and drive organization-wide AI initiatives. \n","\n","pred=SE\n","Work closely with library developers to adopt and use these compiler technologies to enable library development. Work closely with open-source maintainers to have your changes adopted. Work in a distributed compute setting to optimize for both scale-up (multi-GPU) and scale-out (multi-node) systems. \n","\n","pred=ML\n","Research and prototype perception deep learning systems for our level 4 self-driving system. \n","\n","pred=SE\n","Join our core animation technology team and work closely with performance capture, animation, rigging, technical art, and tools teams across different Rockstar studios. Research, develop, maintain, extend, and support a wide range of image/video/mesh processing, surface reconstruction, animation, and rigging performance capture technology, editing pipelines, tools, and runtime systems. Keep up to date with the latest academic and industry breakthroughs, independently research and develop improvements to continuously push our technology forward. \n","\n","pred=ML\n","Collaborate with the application development team to integrate computer vision models with existing backend systems. Collaborate with product leads to design A/B testing experiments with ML technology and improve predictability through end-to-end solutions. Develop CI/CD pipelines for deployment on the cloud. \n","\n","pred=ML\n","Develop metrics that reveal neural network performance, thereby providing actionable information for improving the models. Deploy trained neural networks on a real-time surgical robotic system. \n","\n","pred=ML\n","Building, deploying and maintaining ML models and pipelines. Developing robust and scalable pipelines. Working collaboratively with the ML Lead and the wider team. \n","\n","pred=SE\n","Be a key participant of the team’s Agile process. Actively monitors relevant KPIs for productionized models. Note - Working in a DevOps model, this opportunity includes both building and running solutions that could require off hours support. This support is shared amongst the team members to cover weekends and weeknights. The goal is to design for failure and, using cloud-native infrastructure patterns, automate responses to issues so they can be worked during normal hours. \n","\n","pred=SE\n","Design and implement new models or extend existing models. Develop new visualization techniques. Maintain and develop CI/CD workflows. \n","\n","pred=DS\n","Collaborate with scientists to integrate successful experiments into large scale, highly complex production services. Rapidly design and conduct large scale experiments in a high-ambiguity environment, making use of both quantitative and business judgment. \n","\n","pred=ML\n","Develop new algorithms and approaches to various NLP problems. Conduct quantitative experiments to characterize algorithms. Integrate new technology into core applications. \n","\n","pred=ML\n","Research and develop improvements to our open-banking transaction enrichment pipeline. Lead new projects that improve the capabilities of our open-banking enrichment pipeline (such as transaction categorisation, merchant tagging, and balance prediction). Work as part of the team on downstream tasks like credit risk modelling and fraud detectionImplement, monitor and maintain models in our AWS production environment. \n","\n","pred=ML\n","Designing, training, improving &amp; launching models. Proposing and implementing ideas that directly reduce Stripe’s fraud losses. Building systems that evaluate businesses for risk and take appropriate actions. Working with our partner teams to launch new policies that directly impact Stripe’s bottom line. Debugging production issues across services and multiple levels of the stack. Who you areWe’re looking for someone who meets the minimum requirements to be considered for the role. If you meet these requirements, you are encouraged to apply. The preferred qualifications are a bonus, not a requirement. \n","\n","pred=ML\n","Build state-of-the-art models for various modeling tasks (e.g., NLP, search ranking and recommendation). Optimize and automate model training and testing, experimentation tracking, development, and production. Create ML services/APIs for serving ML/AI model results. Skilled in breaking down problems, documenting problem statements and estimating efforts. \n","\n","pred=ML\n","Create ML pipelines using container native workflow orchestration. Build centralized featureset store for both online and offline training. Support and improve our recommendation pipelines and platform utilizing Spark &amp; (Scala / Python), tooling and integrations with cloud services. Respond to on-calls and alerts on our live pipelines. Participate in discussions, team rituals and be an amplifier to the work of the team. \n","\n","pred=ML\n","Keep track of emerging tech and trends, research the state-of-art deep learning models, prototype new modelling ideas, and conduct offline and online experiments. Mentor other team members, facilitate within/across team workshops and lead the agile development. \n","\n","pred=ML\n","Hands-on in creating architectural prototypes and design implementation to demonstrate the vision in ML/AI solutions and lead the way from concept to realization. May be assigned an Electric Utilities emergency and storm role. This is a special assignment that comes into play during storms and other emergencies when the company needs to restore power or respond to other issues affecting customer service. This role may necessitate the need to work after-hours, outside of your normal schedule. \n","\n","pred=ML\n","Design NLP applications. Use effective text representations to transform natural language into useful features. Find and implement the right algorithms and tools for NLP/ML tasks. Develop ML/NLP systems according to requirements. Perform statistical analysis of results and refine models. \n","\n","pred=ML\n","Participate in cutting-edge applications for neurotechnology and brain-computer interfaces. Utilize cloud compute infrastructure for high-throughput hypothesis modeling and simulation. Translate validated algorithms for clinical deployment (both online and offline). Summarize and communicate results to project teams and contribute to decision-making. Collaborate with the rest of our team to publish and present our work. \n","\n","pred=SE\n","Support and improve our recommendation pipelines and platform utilizing Spark &amp; (Scala / Python), tooling and integrations with cloud services. Enable research scientists to accelerate experimentation using platforms and tools. Create pipelines using container native workflow orchestration. Respond to on-calls and alerts on our live pipelines. Participate in discussions, team rituals and be an amplifier to the work of the team. \n","\n","pred=ML\n","Design and develop state-of-art ML model development and orchestration framework. Design optimal Model run-time instances to improve model run-time, cut-down compute cost. Collaborate with Technical Product Managers to influence the scope, capabilities and roadmap of ML Platform. Articulate and document best practices and design principles to mentor other developers. Research and evaluate new open-source technologies and framework to solve problems &amp; improve existing solutions. Articulate and present the business value of your product design to different stakeholders and user. \n","\n","pred=DS\n","Understand organizational challenges and how integrating AI capabilities can help create solutions. Lead cross-functional teams to identify and prioritize key areas of business where AI solutions can drive significant business benefit. Advise business leaders on a broad range of technology, strategy, and policy issues associated with AI. Document and articulate solution architecture and lessons learned for each exploration and accelerated incubation. Manage a team to conduct assessments of the AI and automation market and competitive landscape. Ensuring that algorithms generate accurate user recommendations. Running tests, performing statistical analysis, and interpreting test results. \n","\n","pred=ML\n","Collaborate with the application development team to integrate computer vision models with existing backend systems. Collaborate with product leads to design A/B testing experiments with ML technology and improve predictability through end-to-end solutions. Develop CI/CD pipelines for deployment on the cloud. \n","\n","pred=DS\n","Work with sales partners to identify business opportunities for advertisers' business goals. \n","\n","pred=SE\n","Follow best practices in development and CI/CD methods and test-driven development. \n","\n","pred=ML\n","Implement and deploy robust audio-related generative models and classifiers. Work closely with researchers to convert research prototypes into production-ready systems. Set up, monitor and maintain inference pipelines. Optimize models for on-device inference. Keep up to date with the latest ML/AI research trends and industry best practices. \n","\n","pred=DS\n","Presenting solutions and technical reasoning to experts and non-experts. \n","\n","pred=ML\n","reinforcement learning, (v)AE, GAN, GCNN. predictive (QSAR) models. knowledge graph mining and analyses algorithms. Present the results of the team findings within the company and at external events. Publish and disseminate your work in research community. Depending on experience, mentoring and line management responsibilities may be part of the role. \n","\n","pred=ML\n","Develop, port, and optimize ML/DL applications and frameworks including HPC use cases for use on AMD hardware. Work with other members of the Applications Solutions team to collaboratively solve issues. Represent AMD to customers and other third parties, and act as the customer advocate when presenting to AMD audiences. Engage with AMD product groups to drive resolution of customer issues. Develop and present training materials to internal audiences, at customer venues, and at industry conferences. \n","\n","pred=DS\n","Implement and test the latest research works. \n","\n","pred=DS\n","Support in building models and algorithms. Meets project deadlines for accountable deliverables and anticipates delays or foreseeable barriers to progress, escalating issues when necessary. Conducts due diligence quality assurance testing for prototypes and tools in beta and resolves reoccurring complex issues and bugs. Experiences Demonstrated success when deciding on technical methodologies for project work. Consistently delivered accurate, technically advanced and valid analyses with impactful insights and conclusions. \n","\n","pred=SE\n","Perform prototyping in real-world and simulation experiments to validate architecture / algorithm designs and technical approaches. Perform troubleshooting to rapidly characterize and address issues within the fleet. \n","\n","pred=ML\n","Build and maintain robust ML pipelines. Implement monitoring systems to track how models are performing. Work to continuously improve model performance and debug where necessary. Manage the memory and computational footprint of our algorithms. \n","\n","pred=SE\n","Collaborate with the Advanced Development Architect and other Product Architects as well as product management team to translate system architecture and product requirements into well implemented components. Contribute as a hands-on Individual Contributor or Project Lead committed to team success, willing to do the simple or complicated tasks to move a project forward. \n","\n","pred=ML\n","You will be the main ML generalist at the organizations, helping provide efficient production and deployment. Please register your interest by sending your CV to Jaashir Morris via the Apply link on this page. \n","\n","pred=SE\n","Promote and support company policies, procedures, mission, values, and standards of ethics and integrity. \n","\n","pred=SE\n","Understand how to break work down into concise deliverables with a focus on iterative product delivery. Own solutions end to end from conception to release by managing complexity and collaboratively working with various stakeholders to achieve desired outcomes. Debug and resolve issues across multiple technology stacks and services. \n","\n","pred=DS\n","Build recommendation and ranking algorithms for news articles. Lead medium/large sized projects to improve news ranking. \n","\n","pred=ML\n","Provide guidance to measure and optimize the quality of deployed algorithms and models ( processes and best practices). Build and maintain the CI/CD pipeline for ML. Be an active member of the business transformationWork with stakeholders including the Executives, CX, Design and Dev teams to assist with related complex technical conversations and support their AI-based product needs. Be an inspirational and motivational colleagueShare knowledge with team members &amp; participate in various learning-sharing activities. Contribute to the collaborative and stimulating work environment. Be a change agent &amp; Agile mindset promoter. Be connected to the industry to know tendencies and suggest innovative ideas. \n","\n","pred=DS\n","Work with stakeholders across hardware, science, and operations teams to iterate on systems design and implementation. Profile, tune, and optimize system performance. Maintain high standards by participating in reviews, designing for fault tolerance and operational excellence, and creating mechanisms for continuous improvement. Mentor junior team members. \n","\n","pred=DS\n","Applied behavioral scientist: Advance the understanding of behavior change and interventions by measuring quantitative and qualitative signals across a breadth of psychographic signals. Act as an owner: It’s not done until it’s in production. Adept at moving projects forward and able to unblock projects regardless of the role on the project. Do less, deliver more: Familiar with the terms YAGNI and yak shaving? Focus your efforts on high impact initiatives that really move the needle. Collaborate without ego: Willing to take on roles small or large in order to further the mission at hand. Stay on your edge: Continuously learning and applying emerging technologies. Pushing yourself and your team to new heights. \n","\n","pred=DS\n","You will be analyzing result sets to identify anomalies and historical norms and order to continuously improve the quality of the model's output and their usefulness in solving real life business problems. \n","\n","pred=ML\n","You will monitor deployed models for model drift and performance, support model retraining and provide incident management support. You will monitor deployed models for model drift and performance, support model retraining and provide incident management support. Bring your passion and expertise 2+ years’ experience deploying AI model pipelines in the Cloud (AWS preferred) and integrating AI/ML and other Cloud services into large-scale production applications. Proficiency in at least one modern programming language like Python and ML frameworks like Tensorflow, Scikit-learn, Pytorch , NumPy, Pandas etc. Solid understanding and 2+ years’ experience working with one of the cloud computing environments such as AWS, Azure, Google Cloud. Must possess strong verbal and written communication skills, be self-driven, accountable and constant learner. Experience working for a large retail company is preferred. \n","\n","pred=ML\n","Communicate and collaborate with a network of experienced architects and designers around the world. Identify complex technical problems, break them down, summarize possible solutions. Work with architects to propose innovative solutions that can be implemented in HW, validated by developing various models/simulators. \n","\n","pred=ML\n","Research and develop innovative ML based solutions to some of Operations' hardest problems. Communicate AI capabilities and results to both technical and non-technical audiences. Document approaches taken, techniques used and processes followed. \n","\n","pred=DS\n","Work with Product Managers to understand the business, formulate the problems, come up with the solutions. \n","\n","pred=ML\n","Collaborate with the application development team to integrate the computer vision models with the existing backend systems. Build monitoring tools and automate the inference pipeline. Develop CI/CD pipelines for deployment on cloud and edge. Inspire the entire team (including your cross-functional) partners by bringing new ideas to the table. \n","\n","pred=SE\n","Responsible for the development and maintenance of key system features. Will work with other team members to investigate design approaches, prototype technology and evaluate technical feasibility. Will establish architectural principles, select design patterns and then mentor team members on their appropriate application. Team Locations:Toronto. Vancouver. Virtual in Canada. Key job responsibilities. \n","\n","pred=SE\n","Pipeline Orchestration – design and development of end to end workflow/pipeline . Assist in development and deployment of automation and operational support strategies. Work in an Agile environment with Scrum teams. \n","\n","pred=SE\n","Build API endpoints. Work on Cloud deployment. \n","\n","pred=SE\n","Monitor, diagnose and maintain deployments. Upgrade systems and models whenever needed. Take care of product performance, robustness and reliability. Manage individual project priorities, deadlines and deliverables. General direction of work involved. \n","\n","pred=ML\n","Implementing appropriate ML algorithms. Demonstrable skill in deep learning (Kaggle Medal / Paper / Work / PhD). Research and implement appropriate ML algorithms and tools. Perform statistical analysis and fine-tuning using test results. Train and retrain systems when necessary. Extend existing ML libraries and frameworks. Keep abreast of developments in the field. \n","\n","pred=DS\n","Define problems and opportunities in a complex business area. Measure the impact of the products developed. \n","\n","pred=ML\n","Collaborate with teams to support the ML technical roadmap. Offer support and troubleshooting assistance for the ML pipeline, while continuously improving stability, monitoring and alerting along the way. Collaborate on managing the AWS stack which comprises all ML resources. Collaborate on managing ML infrastructure costs. \n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"AM8ypTxUM86a","executionInfo":{"status":"ok","timestamp":1660815763541,"user_tz":-540,"elapsed":6,"user":{"displayName":"遠藤巧人","userId":"04831903071860725195"}}},"execution_count":30,"outputs":[]}]}